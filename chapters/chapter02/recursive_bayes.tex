\section{Recursive Bayesian models}
\label{sec:recursive-bayes}

The most challenging problem we face in this application is its \rt{} nature. Vehicle's report their current location, from which we want to estimate road speeds to predict arrival times, all within no more than 30~seconds. Fortunately, a certain class of models suit themselves well to \rt{} applications, and are indeed used in many vehicle tracking and robotics applications \citep{Anderson_1979,Gustafsson_2002,Mutambara_2000}: \glspl{rbm}, sometimes referred to a \emph{sequential Bayesian estimation}.


In a typical analysis, data $\mat{Y}$ would be stored in an $n\times k$ matrix corresponding to $k$ measurements of $n$ variables over time. Then Bayes' rule is used to estimate the posterior distribution of an $m\times k$ matrix of parameters $\mat{X}$ all at once,
\begin{equation}
\label{eq:bayes}
p(\mat{X}\cond{}\mat{Y}) =
\frac{
    p(\mat{X})
    p(\mat{Y}\cond{}\mat{X})
}{
    p(\mat{Y})
},
\end{equation}
using, for example, \agls{mcmc} algorithm. This is usually a computationally intensive procedure and takes much longer than 30~seconds to converge.


In a real-time application, the columns of $\mat{Y}$ are observed sequentially, so that at time $t_k$ we have observed
\begin{equation}
\label{eq:bayes_y_vector}
\mat{Y} = \boldsymbol{y}_{1:k} = [\boldsymbol{y}_1,\cdots,\boldsymbol{y}_k],
\end{equation}
to estimate
\begin{equation}
\label{eq:bayes_x_vector}
\mat{X} = \bx_{0:k} = [\boldsymbol{x}_0,\cdots,\boldsymbol{x}_k],
\end{equation}
where $\boldsymbol{x}_0$ is the \emph{initial state} of the object. Rather than refitting the full model, as would be necessary when using \gls{mcmc}, \gls{rbe} allows us to combine the previous \emph{posterior estimate} of the state with the new information.

\Glspl{rbm} make two general assumptions. The first is that $\boldsymbol{x}$ follows a Markov process such that the state at time $t_k$ depends only upon the state at time $t_{k-1}$:
\begin{equation}
\label{eq:rbe_markov}
p(\boldsymbol{x}_k \cond{} \boldsymbol{x}_{0:k-1}) =
p(\boldsymbol{x}_k \cond{} \boldsymbol{x}_{k-1}).
\end{equation}
The joint distribution of the underlying state parameters is therefore
\begin{equation}
\label{eq:rbe_joint_x}
\begin{split}
p(\bx_{0:k})
&= p(\bx_0)p(\bx_1\cond{}\bx_0)p(\bx_2\cond{}\bx_{0:1})\cdots
p(\bx_{k}\cond{}\bx_{0:k-1}) \\
&= p(\bx_0)p(\bx_1\cond{}\bx_0)p(\bx_2\cond{}\bx_1)\cdots p(\bx_k\cond{}\bx_{k-1}) \\
&= p(\bx_0)\prod_{i=1}^k p(\bx_i\cond{}\bx_{i-1}).
\end{split}
\end{equation}

The second assumption is that the observations $\boldsymbol{y}_k$ of the state depend only on the current state and are independent of one another:
\begin{equation}
\label{eq:rbe_obs}
p(\boldsymbol{y}_k \cond{} \boldsymbol{x}_{0:k}, \boldsymbol{y}_{0:k-1}) =
p(\boldsymbol{y}_k \cond{} \boldsymbol{x}_{k}).
\end{equation}
Thus, the data has joint likelihood
\begin{equation}
\label{eq:rbe_joint_lh}
\begin{split}
p(\boldsymbol{y}_{1:k}\cond{}\bx_{0:k})
&= p(\boldsymbol{y}_1\cond{}\bx_{0:1})\cdots p(\boldsymbol{y}_k\cond{}\bx_{0:k}) \\
&= p(\boldsymbol{y}_1\cond{}\bx_1)\cdots p(\boldsymbol{y}_k\cond{}\bx_k) \\
&= \prod_{i=1}^k p(\boldsymbol{y}_i\cond{}\bx_i)
\end{split}
\end{equation}
and marginal distribution
\begin{equation}
\label{eq:rbe_marginal_y}
p(\boldsymbol{y}_{1:k}) = p(\boldsymbol{y}_1)\cdots p(\boldsymbol{y}_k)
= \prod_{i=1}^k p(\boldsymbol{y}_i).
\end{equation}



We now express the posterior distribution $p(\bx_{0:k}\cond{}\boldsymbol{y}_{1:k})$ using \cref{eq:bayes} along with \cref{eq:rbe_joint_x,eq:rbe_joint_lh,eq:rbe_marginal_y} as
\begin{equation}
\label{eq:rbe_posterior}
\begin{split}
p(\bx_{0:k}\cond{}\boldsymbol{y}_{1:k})
&= \frac{p(\bx_{0:k})p(\boldsymbol{y}_{1:k}\cond{}\bx_{0:k})}{p(\boldsymbol{y}_{1:k})} \\
&= \frac{
    p(\bx_0)\prod_{i=1}^k p(\bx_i) \cdot
    \prod_{i=1}^k p(\boldsymbol{y}_i\cond{}\bx_i)
}{
    \prod_{i=1}^k p(\boldsymbol{y}_i)
} \\
&= p(\bx_0)\prod_{i=1}^k
\frac{
    p(\bx_i) p(\boldsymbol{y}_i\cond{}\bx_i)
}{
    p(\boldsymbol{y}_i)
}.
\end{split}
\end{equation}
However, we can substitute the first $k-1$ terms in \cref{eq:rbe_posterior} to obtain the following recursive representation:
\begin{equation}
\label{eq:rbe_posterior_recursive}
p(\bx_{0:{k}}\cond{}\boldsymbol{y}_{1:k})
= p(\bx_{0:k-1}\cond{}\boldsymbol{y}_{1:k-1})
\frac{
    p(\bx_{k}) p(\boldsymbol{y}_{k}\cond{}\bx_{k})
}{
    p(\boldsymbol{y}_{k})
}.
\end{equation}
Here, the posterior distribution from the previous time step is used as a \emph{prior} for the next, and so it \emph{recursively} (or \emph{sequentially}) updates the state estimate as new data are observed, making \glspl{rbm} ideal for real-time applications.


There are several types of \glspl{rbe} which consist of two main steps: \emph{predict} and \emph{update}. In the prediction step, the algorithm uses a \emph{transition function} $f$ (or matrix $\mat{F}$) to predict the new state based only upon the current state (\cref{eq:rbe_markov}), while the \emph{update} step incorporates the data to adjust the estimate using a \emph{measurement function} $h$ (or matrix $\mat{H}$) describing the relationship between $x$ and $y$ (\cref{eq:rbe_obs}). These can be expressed by the following model equations:
\begin{equation}
\label{eq:rbe_model}
\begin{split}
\bx_k &= f(\bx_{k-1}, \boldsymbol{w}_k) \\
\boldsymbol{y}_k &= h(\bx_k) + \boldsymbol{v}_k
\end{split}.
\end{equation}
The additional parameters $\boldsymbol{w}_k$ and $\boldsymbol{v}_k$ represent \emph{system noise} and \emph{measurement error}, respectively. The choice of $f$, $h$, and the distributions for the error terms depends on the choice of model. We now discuss two types of \gls{rbe} used throughout this thesis: the \kf{} and the \pf{}.


\subsection{\kf{}}
\label{sec:kf}

Commonly used in vehicle tracking applications, the \kf{} is a very fast, simple estimation method \citep{Anderson_1979} that assumes Gaussian errors and represents the state using a multivariate Normal random variable with length $m$ mean vector and $m\times x$ covariance matrix
\begin{equation}
\label{eq:kf_estimators}
\hat\bx_{k|k} = \E{\bx_k | \boldsymbol{y}_{1:k}}
\quad\text{and}\quad
\mat{P}_{k|k} = \Var{\bx_k | \boldsymbol{y}_{1:k}},
\end{equation}
respectively. A \kf{} implementation requires an $m\times m$ \emph{transition matrix}, $\mat{F}_k$, which defines the relationship between states at time $t_{k-1}$ and $t_k$, and an $n\times m$ \emph{measurement matrix}, $\mat{H}_k$, defining the relationship between $\boldsymbol{y}$, a length $n$ vector, and $\bx$, a length $m$ vector.


The \kf{} version of the model presented in \cref{eq:rbe_model} is
\begin{equation}
\label{eq:kf_model}
\begin{split}
\bx_k &= \mat{F}_k\bx_{k-1} + \boldsymbol{w}_k \\
\boldsymbol{y}_k &= \mat{H}_k\bx_k + \boldsymbol{v}_k
\end{split},
\end{equation}
where $\boldsymbol{w}_k$ and $\boldsymbol{v}_k$ are Normal random variables with mean zero and covariance matrices $\mat{Q}_k$ and $\mat{R}_k$, respectively. The $m\times m$ covariance matrix $\mat{Q}_k$ represents the system noise at time $t_k$, which is defined as the rate of change of the variance of process noise \citep{Cathey_2003}. Measurement error is expressed by the $n\times n$ covariance matrix $\mat{R}_k$.

The \kf{} is implemented through two sets of equations. First is the prediction step, in which the current state (represented by the mean vector and covariance matrix) is predicted based solely on the previous state:
\begin{equation}
\label{eq:ch2:kf_predict}
\begin{split}
\hat\bx_{k|k-1} = \E{\bx_k | \bx_{k-1}}
    &= \mat{F}_k \hat\bx_{k-1|k-1} \\
\mat{P}_{k|k-1} = \Var{\bx_k | \bx_{k-1}}
    &= \mat{F}_k \mat{P}_{k-1|k-1} \mat{F}_k^\top + \mat{Q}_k
\end{split}
\end{equation}
Next, the update step uses the observation $\boldsymbol{y}_k$ to adjust the predicted state using the following set of equations, which are effectively taking a ratio of the state and measurement uncertainties:
\begin{equation}
\label{eq:ch2:kf_update}
\begin{split}
\bz_k &= \boldsymbol{y}_k - \mat{H}_k \hat\bx_{k|k-1} \\
\mat{S}_k &= \mat{R}_k + \mat{H}_k \mat{P}_{k|k-1} \mat{H}_k^\top \\
\mat{K}_k &= \mat{P}_{k|k-1} \mat{H}_k^\top \mat{S}_k^{-1} \\
\hat\bx_{k|k} &= \hat\bx_{k|k-1} + \mat{K}_k \bz_k \\
\mat{P}_{k|k} &= (\mat{I} - \mat{K}_k \mat{H}_k) \mat{P}_{k|k-1}
    (\mat{I} - \mat{K}_k \mat{H}_k)^\top + \mat{K}_k \mat{R}_k \mat{K}_k^\top.
\end{split}
\end{equation}


The simplicity of the \kf{} means that, so long as the number of parameters $m$ is small, states can be estimated quickly with minimal processing demand. This simplicity, together with the fact that it provides an exact solution for the multivariate Normal state space model \citep{Anderson_1979}, makes the \kf{} a strong contender for real-time applications. However, it also makes several strong assumptions about the shape of the parameter distributions and is limited to linear relationships between states and measurements since these must be expressed in matrix form.



\subsection{Particle filter}
\label{sec:pf}

Another framework we use is the \pf{}, a more generalised, numerical approach to recursive Bayesian modelling \citep{Gordon_1993}. The state is approximated by a sample of $\Np$ particles, each of which is an independent point estimate of the state, $\bx\vi_k$, with a weight $w\vi \geq 0$ and $\sum_i w\vi = 1$. The state estimate is expressed using the Dirac delta measure $\dirac$ (see \cref{app:dirac-delta-measure} for details), such that
\begin{equation}
\label{eq:pf_state}
p(\bx_{k-1} | \boldsymbol{y}_{1:k-1}) \approx
\sum_{i=1}^\Np w\vi_{k-1} \DiracMeasure{\bx\vi_{k-1}}{\bx_{k-1}}.
\end{equation}

One advantage of the \pf{} is that we are no longer constrained in the choice of transition function, $f$, or the error distribution. Instead of working with the mean and variance of the state (as is the case with the \kf{}) we work with \emph{independent point estimates} which each represent a plausible state. In \cref{cha:vehicle_model} I use a Normal random variable for system noise, but this could be any appropriate distribution (for example a Cauchy if heavier tails are necessary). The state prediction step is carried out independently on each particle,
\begin{equation}
\label{eq:ch2:pf_predict_particle}
\bx\vi_k = f\left(\bx\vi_{k-1}, \boldsymbol{v}\vi_k\right),
\quad
\boldsymbol{v}\vi_k \sim \Normal{\boldsymbol{0}}{\mat{Q}_k}.
\end{equation}
The prior-predictive distribution of the state, using the Dirac delta measure, is given by
\begin{equation}
\label{eq:ch2:pf_predict_state}
p(\bx_k | \bx_{k-1}) \approx
\sum_{i=1}^\Np w\vi_{k-1} \DiracMeasure{\bx\vi_k}{\bx_k}.
\end{equation}


Next, the state is updated to account for the observation using the likelihood function directly. The particles are reweighted and normalised,
\begin{equation}
\label{eq:pf_reweight}
w\vi_k =
\frac{
    w\vi_{k-1} p(\boldsymbol{y}_k | \bx\vi_k)
}{
    \sum_{j=1}^\Np w\vi_{k-1} p(\boldsymbol{y}_k | \bx\vi[j]_k)
},
\end{equation}
which yields the final posterior distribution of the state,
\begin{equation}
\label{eq:pf_state_post}
p(\bx_{k} | \boldsymbol{y}_{1:k}) \approx
\sum_{i=1}^\Np w\vi_{k} \DiracMeasure{\bx\vi_{k}}{\bx_{k}}.
\end{equation}


Over time, many of the particle weights will go to zero as they disperse due to the system noise \citep{Doucet_2000}. This leaves only a few particles contributing to the state, which, if none end near the actual vehicle location, will result in all vehicles having likelihoods close to zero. To prevent this situation of particle filter \emph{degeneration}, we perform \emph{importance resampling} (a weighted bootstrap) in which particles are sampled, with replacement, according to their weight. Afterwards, particle weights are reset to $N^{-1}$.

\citet{Doucet_2000} describe the use of the \emph{effective sample size},
\begin{equation}
    \label{eq:Neff}
    N_{\text{eff}} \approx \frac{1}{\sum_{i=1}^N (w_k\vi)^2},
\end{equation}
which provides an estimate of how varied the particles are: if too few particles contain most of the weight, resampling should occur. This is similar to the Metropolis-Hasting's proposal and acceptance steps: we propose a sample of state estimates and reject those that are not plausible given the data. If the system noise (proposal distribution) is small, then more particles will be ``accepted'', but we may not propose sufficient trajectories. Conversely, if the noise is too large, then there will be many ``rejections'', reducing the variety of particles (small $N_\text{eff}$).

Another advantage of the \pf{} is its generality. As we discuss in \cref{sec:vehicle_model}, we can easily construct a transition function to describe a complex system, as well as define a likelihood function that accurately represents the relationship between observed and unobserved states.

The main disadvantage is, of course, that the computational demand is high, as each particle is transitioned independently, and resampling can be slow for large $\Np$, having order $\mathcal{O}(\Np\log\Np)$ in the \prog{C++} algorithm we use. However, as we discuss in the next chapter, the advantages far outweigh the additional computational demands of the \pf{}, which can be minimised if implemented carefully.
