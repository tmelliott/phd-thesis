\section{Modelling \rt{} data: recursive Bayes}
\label{sec:recursive-bayes}

Now that we have discussed how the data is structured,
we need to consider how it can be modelled.
The main point to consider is that the data are being collected in \rt{},
in order to make predictions of arrial time \emph{in \rt{}}.
Therefore, the modelling framework is tightly constrained by
the necessity that it can be run quickly.
We are working with vehicle location data,
with the goal of estimating the location and speed of a vehicle,
collectively referred to as its \emph{state},
which we will (for now) denote $\bx$.
This state changes over time, so we denote a particular instance of the state
at a time $t_k$ using a subscript, $\bx_k$.


However, we cannot observe the state of the vehicle directly;
instead we get observations $\bz_k$, from which we wish to infer the underlying state.







\pagebreak

In many data analysis situations,
data is observed and stored in an $n\times m$ matrix which, for generality,
will be denoted $\boldsymbol{\mathcal{Y}}$ in this section.
We could then implement a model and estimate all of the parameters at once,
for example by using \gls{mcmc},
to estimate some matrix of parameters $\boldsymbol{\mathcal{X}}$
that correspond to the values we are interested in (the speed of vehicles),
using the well known Bayes' formula,
\begin{equation}
\label{eq:bayes}
p(\boldsymbol{\mathcal{X}}|\boldsymbol{\mathcal{Y}}) =
\frac{
    p(\boldsymbol{\mathcal{X}})
    p(\boldsymbol{\mathcal{Y}}|\boldsymbol{\mathcal{X}})
}{
    p(\boldsymbol{\mathcal{Y}})
}
\end{equation}

In \rt{} applications, as are many vehicle tracking problems,
the data is observed \emph{and modelled} in \rt{}.
That is, at time $t_k$, we recieve an observation as a column vector
$\boldsymbol{\mathcal{Y}}_k$ of length $n$,
and want to estimate the state of the vehicle
$p(\boldsymbol{\mathcal{X}}_{0:k}|\boldsymbol{\mathcal{Y}}_{1:k})$.
Of course, we could just fit a full Bayesian model to the new data,
but this will take time,
and will involve a lot of refitting data that is not only already estimated,
but no longer necessary
(we no longer care about the vehicle state at any time before $t_k$).
Instead, it is common for \rt{} applications to use a recursive estimation algorithm.




The general principal behind recursive Bayesian estimation,
or \emph{sequential Bayes},
is that there exists some underlying Markov process with state $x_k$,
of which observations $z_k$ are made.
The assumption that the process is Markov---which means that the current state
depends only on the previous state, and is indepenent of all others---gives
\begin{equation}
\label{eq:rbe_markov}
p(\boldsymbol{\mathcal{X}}_k | \boldsymbol{\mathcal{X}}_{k-1}, \ldots, \boldsymbol{\mathcal{X}}_{0}) =
p(\boldsymbol{\mathcal{X}}_k | \boldsymbol{\mathcal{X}}_{k-1})
\end{equation}
and, since the observation at time $t_k$ is dependentent only on the state at time $t_k$,
we have that
\begin{equation}
\label{eq:rbe_obs}
p(\boldsymbol{\mathcal{Y}}_k | \boldsymbol{\mathcal{X}}_{k}, \ldots, \boldsymbol{\mathcal{X}}_{0}) =
p(\boldsymbol{\mathcal{Y}}_k | \boldsymbol{\mathcal{X}}_{k}).
\end{equation}


Now, the numerator from \cref{eq:bayes} can be re-expressed,
first by showing that
\begin{align}
\label{eq:rbe_join_x}
p(\boldsymbol{\mathcal{X}}_{0:k}) &=
p(\boldsymbol{\mathcal{X}}_{0},\boldsymbol{\mathcal{X}}_{1},\ldots,\boldsymbol{\mathcal{X}}_{k}) \nonumber\\
&= p(\boldsymbol{\mathcal{X}}_{0}) p(\boldsymbol{\mathcal{X}}_{1} | \boldsymbol{\mathcal{X}}_{0})
    p(\boldsymbol{\mathcal{X}}_{2} | \boldsymbol{\mathcal{X}}_{1}, \boldsymbol{\mathcal{X}}_{0}) \cdots
    p(\boldsymbol{\mathcal{X}}_{k} | \boldsymbol{\mathcal{X}}_{k-1}, \ldots, \boldsymbol{\mathcal{X}}_{0})
    \nonumber\\
\intertext{which can be simplified using \cref{eq:rbe_markov} to}
p(\boldsymbol{\mathcal{X}}_{0:k})
&= p(\boldsymbol{\mathcal{X}}_{0})
    p(\boldsymbol{\mathcal{X}}_{1} | \boldsymbol{\mathcal{X}}_{0})
    p(\boldsymbol{\mathcal{X}}_{2} | \boldsymbol{\mathcal{X}}_{1}) \cdots
    p(\boldsymbol{\mathcal{X}}_{k} | \boldsymbol{\mathcal{X}}_{k-1}) \nonumber\\
&= p(\boldsymbol{\mathcal{X}}_{0})
    \prod_{i=1}^k p(\boldsymbol{\mathcal{X}}_{i} | \boldsymbol{\mathcal{X}}_{i-1})
\end{align}
Secondly, using \cref{eq:rbe_obs}, the rest of the numerator becomes
\begin{align}
\label{eq:rbe_join_y}
p(\boldsymbol{\mathcal{Y}}_{1:k} | \boldsymbol{\mathcal{X}}_{0:k}) &=
p(\boldsymbol{\mathcal{Y}}_{1} | \boldsymbol{\mathcal{X}}_{1}) \cdots
p(\boldsymbol{\mathcal{Y}}_{k} | \boldsymbol{\mathcal{X}}_{k}) \nonumber \\
&= \prod_{i=1}^k p(\boldsymbol{\mathcal{Y}}_{i} | \boldsymbol{\mathcal{X}}_{i})
\end{align}


% Now, we can express \cref{eq:bayes} by substituting \cref{eq:rbe_join_x,eq:rbe_join_y},
% \begin{align}
% \label{eq:rbe_bayes}

% \end{align}



% with transition function $\mathcal{F}$
% and system noise $\mathcal{Q}$,
% \begin{equation}
% \label{eq:markov_state}
% \mathcal{X}_k = \mathcal{F}(\mathcal{X}_{k-1}, \mathcal{Q}_k).
% \end{equation}
% The important aspect of this is that the current state
% depends only on the previous state,
% % \begin{equation}
% % \label{eq:state_dist}
% % p(\mathcal{X}_k | \mathcal{X}_0, \ldots, \mathcal{X}_{k-1}) =
% % p(\mathcal{X}_k | \mathcal{X}_{k-1})
% % \end{equation}
% which allows us to model the current state using only the previous one,
% which speeds up processing time.
% How this is done depends on the estimator being used.


% The second part of recursive Bayes regards how the object is observed.
% In many cases, it is impossible to measure the desired state directly,
% so instead a related, \emph{observable} state is measured,
% $\mathcal{Y}$, which is related to the underlying state through
% the measurement function $\mathcal{H}$
% and measurement error $\mathcal{R}$,
% \begin{equation}
% \label{eq:state_measure}
% \mathcal{Y}_k = \mathcal{H}(\mathcal{X}_k, \mathcal{R})
% \end{equation}
% It is of interest to estimate the current state
% based on all of the observations so far,
% \begin{equation}
% \label{eq:state_dist_obs}
% p(\mathcal{X}_k | \mathcal{Y}_{1:k})
% \end{equation}
% which can be done recursively each time a new observation is recieved.

% The general formula for recusive Bayes models is
% to first \emph{predict} the next state,
% $p(\mathcal{X}_k | \mathcal{X}_{k-1})$,
% and then to update the prediction using the likelihood
% $p(\mathcal{Y}_k | \mathcal{X}_k)$
% to obtain a posterior estimate of the state
% given all previous observations,
% $p(\mathcal{X}_k | \mathcal{Y}_{1:k})$.


% There are several different estimation techniques,
% from emperical ones such as the \emph{\kf{}}
% and it's variants (Extendend \kf{}, etc.),
% to numerical ones such as the \pf{}.
% Here we will discuss the \kf{} and the \pf{},
% which we will be using in later sections.


\subsection{\kf{}}
\label{sec:kf}

Commonly used in vehilce tracking applications,
the \kf{} is a very fast, simple estimation method
that assumes Gaussian noise and approximates the state
by a normal random variable with mean and variance
\begin{equation}
\label{eq:kf_estimators}
\begin{split}
\mathcal{\hat X}_{k|k} &= \E{\mathcal{X}_k | \mathcal{Y}_{1:k}} \\
\mathcal{P}_{k|k} &= \Var{\mathcal{X}_k | \mathcal{Y}_{1:k}}
\end{split}.
\end{equation}
The transition and measurement functions
at time $t_k$ are expressed as matrices
$\mat{F}_k$ and $\mat{H}_k$, respectively.
The system noise $\vec{q}_k$ and measurement error $\vec{r}_k$
at time $t_k$ are both random normal variables
with mean vector $\vec{0}$ and covariance matrices
$\mat{Q}_k$ and $\mat{R}_k$, respectively.
Therefore, the \kf{} prediction step is
\begin{equation}
\label{eq:kf_predict}
\begin{split}
\mathcal{\hat X}_{k|k-1} = \E{\mathcal{X}_k | \mathcal{X}_{k-1}}
    &= \mat{F}_k \mathcal{\hat X}_{k-1|k-1} + \vec{q}_k \\
\mathcal{P}_{k|k-1} = \Var{\mathcal{X}_k | \mathcal{X}_{k-1}}
    &= \mat{F}_k \mathcal{P}_{k-1|k-1} \mat{F}_k^\top + \mat{Q}_k
\end{split}
\end{equation}

\mathbf{Q is the \emph{rate of change of the variance of
process noise}} \citep{Cathey_2003}.

The update step is also simple,
and expressed as a series of equations:
\begin{equation}
\label{eq:kf_update}
\begin{split}
\mathcal{\tilde Z}_k &= \mathcal{Y}_k - \mat{H}_k \mathcal{\hat X}_{k|k-1} \\
\mat{S}_k &= \mat{R}_k + \mat{H}_k \mathcal{P}_{k|k-1} \mat{H}_k^\top \\
\mat{K}_k &= \mathcal{P}_{k|k-1} \mat{H}_k^\top \mat{S}_k^{-1} \\
\mathcal{\hat X}_{k|k} &= \mathcal{\hat X}_{k|k-1} + \mat{K}_k \mathcal{\tilde Z}_k \\
\mathcal{P}_{k|k} &= (\mat{I} - \mat{K}_k \mat{H}_k) \mathcal{P}_{k|k-1}
    (\mat{I} - \mat{K}_k \mat{H}_k)^\top + \mat{K}_k \mat{R}_k \mat{K}_k^\top
\end{split}
\end{equation}
The main point to make here is that the measurement matrix,
blah blah blah thing about the thing goes here.



\subsection{Particle filter}
\label{sec:pf}

The other framework we use is the \pf{},
a more generalised, numerical approach to recursive Bayesian modelling.
The state is approximated by a sample of $\Np$ particles,
each of which is an independent point estimate of the state with a weight $\Pwt$
such that $\Pwt\geq 0$ and $\sum_i \Pwt = 1$.
The state estimate is expressed using the Dirac delta function $\dirac$ \citep{cn},
such that
\begin{equation}
\label{eq:pf_state}
p(\mathcal{X}_{k-1} | \mathcal{Y}_{1:k-1}) \approx
\sum_{i=1}^\Np \Pwt_{k-1} \dirac(\mathcal{X}_{k-1} - \mathcal{X}\vi_{k-1})
\end{equation}

The predict and updates steps,
also referred to by \emph{mutate} and \emph{select},
are as follows.

The prediction step applies the transition function $\mathcal{F}_k$
to each particle independently,
diversifying of ``mutating'' the sample.
For each particle, this is
\begin{equation}
\label{eq:pf_predict}
\mathcal{X}\vi_k = \mathcal{F}\left(\mathcal{X}\vi_{k-1}, q\vi_k\right),
\quad
q\vi_k \sim \Normal{0}{\mathcal{Q}_k}
\end{equation}
where the noise can be incorporated in any logical way.

The state estimate is now
\begin{equation}
\label{eq:pf_predict}
p(\mathcal{X}_k | \mathcal{X}_{k-1}) \approx
\sum_{i=1}^\Np \Pwt_{k-1} \dirac(\mathcal{X}_k - \mathcal{X}\vi_k)
\end{equation}


The next step is to update the state
to account for the observation
by using the likelihood function directly.
This is simply done by reweighting each particle
using the likleihood,
and dividing by the sum to ensure they sum to 1:
\begin{equation}
\label{eq:pf_reweight}
\Pwt_k =
\frac{
    \Pwt_{k-1} p(\mathcal{Y}_k | \mathcal{X}\vi_k)
}{
    \sum_{j=1}^\Np \Pwt[j]_{k-1} p(\mathcal{Y}_k | \mathcal{X}\vi[j]_k)
}
\end{equation}


Over time, the mutation step will diversity the particles
to the point where very few of the particles contribute all of the weight.
To prevent the \pf{} from degenerating like this,
importance resampling (weighted bootstrap)
is performed to \emph{select} the best approximation of the state.
Afterwards, the particles are all reweighted with weight $\Pwt_k = \Np^{-1}$.


The advantage of the \pf{} is that it is general,
at as we will see in \cref{sec:vehicle_model},
we can easily create a transition function to describe a complex system,
and the likelihood is intuitive and does not require map matching.

The disadvantage is, of course,
that the computational demand is high,
as each particle is translated independently,
and then resampling can be slow for large $\Np$,
having order $\mathcal{O}(\Np\log\Np)$ in the C++ algorithm we use.
However, the tradeoffs are massive as we will discuss in the next chapter.
