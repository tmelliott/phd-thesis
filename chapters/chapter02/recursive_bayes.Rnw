\section{Recursive Bayesian models}
\label{sec:recursive-bayes}

The most challenging problem we face in this application is its \rt{} nature. Vehicle's report their current location, from which we want to estimate road speeds in order to predict arrival times, all within no more than 30~seconds. Fortunately, a certain class of models suit themselves well to \rt{} applications, and are indeed used in many vehicle tracking and robotis applications. These are, of course, \glspl{rbm}, sometimes referred to a \emph{sequential Bayes}.


In a typical analysis, data $\mat{Y}$ would be stored in an $n\times k$ matrix corresponding to $k$ measurements of $n$ variables over time. Then Bayes' rule could be used to estimate the posterior distribution of an $m\times k$ matrix of parameters $\mat{X}$ all at once,
\begin{equation}
\label{eq:bayes}
p(\mat{X}\cond{}\mat{Y}) =
\frac{
    p(\mat{X})
    p(\mat{Y}\cond{}\mat{X})
}{
    p(\mat{Y})
}
\end{equation}
This is typically estimated using an \gls{mcmc} algorithm, which are generally computationally intensive and take much longer than 30~seconds to converge.
In a \rt{} application, the columns of $\mat{Y}$ are observed sequentially, so that at time $t_k$ we have observed
\begin{equation}
\label{eq:bayes_y_vector}
\mat{Y}_{1:k} = [\boldsymbol{y}_1,\cdots,\boldsymbol{y}_k],
\end{equation}
and wish to estimate
\begin{equation}
\label{eq:bayes_x_vector}
\mat{X}_{0:k} = [\boldsymbol{x}_0,\cdots,\boldsymbol{x}_k],
\end{equation}
where $\boldsymbol{x}_0$ is the \emph{initial state} of the object being modelled. Rather than refitting the full model, as we would need to do using \gls{mcmc}, \gls{rbe} allows us to combine the previous \emph{posterior estimate} of the state with the new information.

In a \gls{rbm}, we make two general assumptions. The first is that $\boldsymbol{x}$ follows a Markov process such that the state at time $t_k$ depends only upon the state at time $t_{k-1}$:
\begin{equation}
\label{eq:rbe_markov}
p(\boldsymbol{x}_k \cond{} \boldsymbol{x}_{k-1}, \ldots, \boldsymbol{x}_{0}) =
p(\boldsymbol{x}_k \cond{} \boldsymbol{x}_{k-1})
\end{equation}
from which we can derive the joint distribution of the underlying state parameters
\begin{equation}
\label{eq:rbe_joint_x}
\begin{split}
p(\mat{X}_{0:k})
&= p(\bx_0)p(\bx_1\cond{}\bx_0)p(\bx_2\cond{}\bx_1,\bx_0)\cdots
p(\bx_{k}\cond{}\bx_{k-1},\ldots,\bx_0) \\
&= p(\bx_0)p(\bx_1\cond{}\bx_0)p(\bx_2\cond{}\bx_1)\cdots p(\bx_k\cond{}\bx_{k-1}) \\
&= p(\bx_0)\prod_{i=1}^k p(\bx_i\cond{}\bx_{i-1})
\end{split}
\end{equation}

The second assumption is that the \emph{observations} $\boldsymbol{y}_k$ of the state depend only on the current state and are independent of one another:
\begin{equation}
\label{eq:rbe_obs}
p(\boldsymbol{y}_k \cond{} \boldsymbol{x}_{k}, \ldots, \boldsymbol{x}_{0},
\boldsymbol{y}_{k-1}, \ldots, \boldsymbol{y}_{1}) =
p(\boldsymbol{y}_k \cond{} \boldsymbol{x}_{k}).
\end{equation}
This allows us to derive the joint likelihood for the data,
\begin{equation}
\label{eq:rbe_joint_lh}
\begin{split}
p(\mat{Y}_{1:k}\cond{}\mat{X}_{0:k})
&= p(\boldsymbol{y}_1\cond{}\bx_1,\bx_0)\cdots p(\boldsymbol{y}_k\cond{}\bx_k,\ldots,\bx_0) \\
&= p(\boldsymbol{y}_1\cond{}\bx_1)\cdots p(\boldsymbol{y}_k\cond{}\bx_k) \\
&= \prod_{i=1}^k p(\boldsymbol{y}_i\cond{}\bx_i)
\end{split}
\end{equation}
along with the marginal distribution for the data,
\begin{equation}
\label{eq:rbe_marginal_y}
p(\mat{Y}_{1:k}) = p(\boldsymbol{y}_1)\cdots p(\boldsymbol{y}_k)
= \prod_{i=1}^k p(\boldsymbol{y}_i)
\end{equation}



We can now express the posterior distribution $p(\mat{X}_{0:k}\cond{}\mat{Y}_{1:k})$ using \cref{eq:bayes} along with \cref{eq:rbe_joint_x,eq:rbe_joint_lh,eq:rbe_marginal_y} as
\begin{equation}
\label{eq:rbe_posterior}
\begin{split}
p(\mat{X}_{0:k}\cond{}\mat{Y}_{1:k})
&= \frac{p(\mat{X}_{0:k})p(\mat{Y}_{1:k}\cond{}\mat{X}_{0:k})}{p(\mat{Y}_{1:k})} \\
&= \frac{
    p(\bx_0)\prod_{i=1}^k p(\bx_i) \cdot
    \prod_{i=1}^k p(\boldsymbol{y}_i\cond{}\bx_i)
}{
    \prod_{i=1}^k p(\boldsymbol{y}_i)
} \\
&= p(\bx_0)\prod_{i=1}^k
\frac{
    p(\bx_i) p(\boldsymbol{y}_i\cond{}\bx_i)
}{
    p(\boldsymbol{y}_i)
}
\end{split}
\end{equation}

Finally, when we to receive new data $\boldsymbol{y}_{k+1}$, the posterior distribution of the underlying state parameters using \cref{eq:rbe_posterior} is
\begin{equation}
\label{eq:rbe_posterior2}
\begin{split}
p(\mat{X}_{0:k+1}\cond{}\mat{Y}_{1:k+1})
&= p(\bx_0)\prod_{i=1}^{k+1}
\frac{
    p(\bx_i) p(\boldsymbol{y}_i\cond{}\bx_i)
}{
    p(\boldsymbol{y}_i)
} \\
&= p(\bx_0)\prod_{i=1}^k
\frac{
    p(\bx_i) p(\boldsymbol{y}_i\cond{}\bx_i)
}{
    p(\boldsymbol{y}_i)
}
\cdot
\frac{
    p(\bx_{k+1}) p(\boldsymbol{y}_{k+1}\cond{}\bx_{k+1})
}{
    p(\boldsymbol{y}_{k+1})
} \\
&= p(\mat{X}_{0:k}\cond{}\mat{Y}_{1:k})
\frac{
    p(\bx_{k+1}) p(\boldsymbol{y}_{k+1}\cond{}\bx_{k+1})
}{
    p(\boldsymbol{y}_{k+1})
}.
\end{split}
\end{equation}
Here, the posterior distribution from the previous time step is used as a \emph{prior} for the next, and so it \emph{recursively} or \emph{sequentially} updates the state estimate as new data are observed. This is what makes \glspl{rbm} perfect for use in \rt{} applications.


There are several types of \glspl{rbe}, but they all consist of two main steps: the \emph{prediction}, and the \emph{update}. In the prediction step, the algorithm uses a \emph{transition function} $f$ (or matrix) to predict the new state based only upon the current state, while the \emph{update} step incorporates the data to adjust the estimate using a \emph{measurement function} $h$, which describes the relationship between $x$ and $y$. These can be expressed by the following model equations:
\begin{equation}
\label{eq:rbe_model}
\begin{split}
\bx_k &= f(\bx_{k-1}, \boldsymbol{w}_k) \\
\boldsymbol{y}_k &= h(\bx_k) + \boldsymbol{v}_k.
\end{split}
\end{equation}
The additional parameters $\boldsymbol{w}_k$ and $\boldsymbol{v}_k$ represent \emph{system noise} and \emph{measurement error}, respectively. The choice of $f$, $h$, and the distributions for the error terms depends on the choice of model. We now discuss two types of \gls{rbe} which are used throughout this work: the \kf{} and the \pf{}.


\subsection{\kf{}}
\label{sec:kf}

Commonly used in vehilce tracking applications,
the \kf{} is a very fast, simple estimation method
that assumes Gaussian noise and approximates the state
by a normal random variable with mean and variance
\begin{equation}
\label{eq:kf_estimators}
\begin{split}
\mathcal{\hat X}_{k|k} &= \E{\mathcal{X}_k | \mathcal{Y}_{1:k}} \\
\mathcal{P}_{k|k} &= \Var{\mathcal{X}_k | \mathcal{Y}_{1:k}}
\end{split}.
\end{equation}
The transition and measurement functions
at time $t_k$ are expressed as matrices
$\mat{F}_k$ and $\mat{H}_k$, respectively.
The system noise $\vec{q}_k$ and measurement error $\vec{r}_k$
at time $t_k$ are both random normal variables
with mean vector $\vec{0}$ and covariance matrices
$\mat{Q}_k$ and $\mat{R}_k$, respectively.
Therefore, the \kf{} prediction step is
\begin{equation}
\label{eq:ch2:kf_predict}
\begin{split}
\mathcal{\hat X}_{k|k-1} = \E{\mathcal{X}_k | \mathcal{X}_{k-1}}
    &= \mat{F}_k \mathcal{\hat X}_{k-1|k-1} + \vec{q}_k \\
\mathcal{P}_{k|k-1} = \Var{\mathcal{X}_k | \mathcal{X}_{k-1}}
    &= \mat{F}_k \mathcal{P}_{k-1|k-1} \mat{F}_k^\top + \mat{Q}_k
\end{split}
\end{equation}

$\mathbf{Q}$ is the \emph{rate of change of the variance of
process noise} \citep{Cathey_2003}.

The update step is also simple,
and expressed as a series of equations:
\begin{equation}
\label{eq:ch2:kf_update}
\begin{split}
\mathcal{\tilde Z}_k &= \mathcal{Y}_k - \mat{H}_k \mathcal{\hat X}_{k|k-1} \\
\mat{S}_k &= \mat{R}_k + \mat{H}_k \mathcal{P}_{k|k-1} \mat{H}_k^\top \\
\mat{K}_k &= \mathcal{P}_{k|k-1} \mat{H}_k^\top \mat{S}_k^{-1} \\
\mathcal{\hat X}_{k|k} &= \mathcal{\hat X}_{k|k-1} + \mat{K}_k \mathcal{\tilde Z}_k \\
\mathcal{P}_{k|k} &= (\mat{I} - \mat{K}_k \mat{H}_k) \mathcal{P}_{k|k-1}
    (\mat{I} - \mat{K}_k \mat{H}_k)^\top + \mat{K}_k \mat{R}_k \mat{K}_k^\top
\end{split}
\end{equation}
The main point to make here is that the measurement matrix,
blah blah blah thing about the thing goes here.



\subsection{Particle filter}
\label{sec:pf}

The other framework we use is the \pf{},
a more generalised, numerical approach to recursive Bayesian modelling.
The state is approximated by a sample of $\Np$ particles,
each of which is an independent point estimate of the state with a weight $\Pwt$
such that $\Pwt\geq 0$ and $\sum_i \Pwt = 1$.
The state estimate is expressed using the Dirac delta function $\dirac$ \citep{cn},
such that
\begin{equation}
\label{eq:pf_state}
p(\mathcal{X}_{k-1} | \mathcal{Y}_{1:k-1}) \approx
\sum_{i=1}^\Np \Pwt_{k-1} \dirac(\mathcal{X}_{k-1} - \mathcal{X}\vi_{k-1})
\end{equation}

The predict and updates steps,
also referred to by \emph{mutate} and \emph{select},
are as follows.

The prediction step applies the transition function $\mathcal{F}_k$
to each particle independently,
diversifying of ``mutating'' the sample.
For each particle, this is
\begin{equation}
\label{eq:ch2:pf_predict_particle}
\mathcal{X}\vi_k = \mathcal{F}\left(\mathcal{X}\vi_{k-1}, q\vi_k\right),
\quad
q\vi_k \sim \Normal{0}{\mathcal{Q}_k}
\end{equation}
where the noise can be incorporated in any logical way.

The state estimate is now
\begin{equation}
\label{eq:ch2:pf_predict_state}
p(\mathcal{X}_k | \mathcal{X}_{k-1}) \approx
\sum_{i=1}^\Np \Pwt_{k-1} \dirac(\mathcal{X}_k - \mathcal{X}\vi_k)
\end{equation}


The next step is to update the state
to account for the observation
by using the likelihood function directly.
This is simply done by reweighting each particle
using the likleihood,
and dividing by the sum to ensure they sum to 1:
\begin{equation}
\label{eq:pf_reweight}
\Pwt_k =
\frac{
    \Pwt_{k-1} p(\mathcal{Y}_k | \mathcal{X}\vi_k)
}{
    \sum_{j=1}^\Np \Pwt[j]_{k-1} p(\mathcal{Y}_k | \mathcal{X}\vi[j]_k)
}
\end{equation}


Over time, the mutation step will diversity the particles
to the point where very few of the particles contribute all of the weight.
To prevent the \pf{} from degenerating like this,
importance resampling (weighted bootstrap)
is performed to \emph{select} the best approximation of the state.
Afterwards, the particles are all reweighted with weight $\Pwt_k = \Np^{-1}$.


The advantage of the \pf{} is that it is general,
at as we will see in \cref{sec:vehicle_model},
we can easily create a transition function to describe a complex system,
and the likelihood is intuitive and does not require map matching.

The disadvantage is, of course,
that the computational demand is high,
as each particle is translated independently,
and then resampling can be slow for large $\Np$,
having order $\mathcal{O}(\Np\log\Np)$ in the C++ algorithm we use.
However, the tradeoffs are massive as we will discuss in the next chapter.
