\subsection{Real-time performance of the \pf{}}
\label{sec:pf_issues}



The two components of the model to assess are the iteration timings and the performance of the particle filter itself. That is, does the program run fast enough to be feasible in real-time, and is the model (and its \pf{} implementation) capable of modelling a transit vehicle in \rt{}?


\paragraph{Is the particle filter fast enough?}
At peak hour on a typical weekday morning, there can be in excess of 1000~buses operating in Auckland. This leads to having more than $1000\Np$~particles in memory, each being mutated and reweighted approximately once every 30~seconds or so. By varying $N$, we can control how quickly each set of observations is processed. \Cref{fig:pf_timings} shows the average timings of the vehicle model component of our application, as well as the average time per particle. More particles require more processing power, though there is additional overhead during the \emph{resampling} phase. Limiting the frequency of resampling is therefore necessary to make the program run faster. This is why we use the effective sample size, $\Neff$.


<<pf_timings,echo=FALSE,message=FALSE,cache=TRUE,fig.width=6,fig.height=3,out.width=".8\\textwidth",fig.align="center",fig.cap="Timings.">>=
suppressPackageStartupMessages(library(tidyverse))

times <- do.call(
    bind_rows,
    lapply(
        list.files("~/Documents/uni/transitr/simulations/oldsim2",
            pattern = "sim_",
            full = TRUE
        ),
        function(dir) {
            if (!file.exists(file.path(dir, "timings.csv"))) return(NULL)
            sim <- basename(dir)
            siminfo <- strsplit(sim, "_")[[1]][-1]
            if (grepl("e", siminfo[3])) siminfo[3] <- format(as.numeric(siminfo[3]), scientific = FALSE)
            siminfo <- as.numeric(gsub("-", ".", siminfo))
            read_csv(file.path(dir, "timings.csv")) %>%
                mutate(
                    sim = sim,
                    n_particles = siminfo[1],
                    gps_error = siminfo[2],
                    system_noise = siminfo[3],
                    timestamp = as.POSIXct(timestamp, origin = "1970-01-01")
                )
        }
    )
)
date <- format(times$timestamp[1], "%Y-%m-%d")
trange <- as.POSIXct(paste(date, c("13:30", "14:00")))

tsmry <- times %>%
    filter(
        what == "updating vehicle states" &
        timestamp >= trange[1] & timestamp <= trange[2]
    ) %>%
    group_by(sim) %>%
    summarize(
        cpu = mean(cpu),
        wall = mean(wall),
        n_particles = first(n_particles),
        gps_error = first(gps_error),
        system_noise = first(system_noise)
    ) %>%
    ungroup()

p0 <- tsmry %>%
    group_by(n_particles) %>%
    summarize(wall = mean(wall)) %>%
    ggplot(aes(y = n_particles)) +
        theme_classic() +
        scale_y_continuous("Number of particles")

p1 <- p0 +
    geom_segment(
        aes(x = wall, xend = 0, yend = n_particles)
    ) +
    geom_point(aes(wall)) +
    scale_x_continuous("Average iteration time (ms)")

p2 <- p0 +
    geom_segment(
        aes(x = wall / n_particles, xend = 0, yend = n_particles)
    ) +
    geom_point(aes(wall / n_particles)) +
    scale_x_continuous("Time per particle (ms)")

library(patchwork)
p1 + p2
@


\paragraph{How does the model perform?}


<<model_performance_prep,echo=FALSE,message=FALSE,cache=TRUE>>=

suppressPackageStartupMessages(library(tidyverse))

get_sim_files <- function(sim) {
    simfile <- file.path(
        "simdata",
        sim,
        "modeleval.rds"
    )
    if (file.exists(simfile)) {
        return(readRDS(simfile))
    }
    zipfile <- "~/Documents/uni/transitr/simulations/oldsim2.zip"
    x <- try({
        siminfo <- strsplit(sim, "_")[[1]][-1]
        if (grepl("e", siminfo[3]))
            siminfo[3] <- format(as.numeric(siminfo[3]), scientific = FALSE)
        siminfo <- as.numeric(gsub("-", ".", siminfo))

        zfiles <- unzip(zipfile, list = TRUE)
        zfiles <- zfiles[
            grepl(sim, zfiles$Name) &
            grepl("modeleval/vehicle_[A-Z0-9]+\\.csv", zfiles$Name),
            ]

        library(parallel)
        cl <- makeCluster(4L)
        on.exit(stopCluster(cl))
        clusterExport(cl, c("zipfile"))
        clusterEvalQ(cl, library(magrittr))
        do.call(bind_rows,
            pbapply::pblapply(sample(zfiles$Name),
                function(x) {
                    print(x)
                    tf <- unzip(zipfile, files = x)
                    on.exit(unlink(tf))
                    readr::read_csv(tf,
                        col_names = c(
                            "vehicle_id", "trip_id", "ts", "prior_mse",
                            "posterior_mse", #"sumwt", "varwt",
                            "post_speed", "prior_speed_var",
                            "posterior_speed_var", "dist_to_path",
                            "Neff", "resample", "n_resample", "bad_sample"
                        ),
                        col_types = "ccidddddddiii",
                        progress = FALSE
                    ) %>%
                        dplyr::mutate(
                            ts = as.POSIXct(ts, origin = "1970-01-01")
                        )
                },
                cl = cl
            )
        ) %>% mutate(
            sim = sim,
            n_particles = siminfo[1],
            gps_error = siminfo[2],
            system_noise = siminfo[3]
        )
    }, silent = TRUE)
    if (inherits(x, "try-error")) return(NULL)
    dir.create(dirname(simfile), recursive = TRUE)
    saveRDS(x, simfile)
    x
}

zipfile <- "~/Documents/uni/transitr/simulations/oldsim2.zip"
zfiles <- unzip(zipfile, list = TRUE)
sims <- unique(sapply(str_split(zfiles$Name, "/"), function(p) p[2]))
sims <- sims[grepl("^sim_", sims)]
res <- do.call(bind_rows, pbapply::pblapply(sims, get_sim_files))

@


To assess how well our model performs in \rt{}, we repeated the simulation with a range of values of system noise $\Vnoise$, GPS error $\GPSerr$, and number of particles $\Np$. For each simulation, we computed \emph{proportional effective sample size}, \emph{degeneration rate}, and \emph{relative variance}.

The \emph{proportional effective sample size} is simply a measure of the proportion of effective sample size, $\tilde\Neff = \frac{\Neff}{\Np}$. The higher this value, the less often the vehicle's state needs resampling, which decreases the average iteration time. \Cref{fig:model_performance_neff} shows the effect of $\Np$, system noise, and GPS error on $\tilde\Neff$. The most striking relationship is between $\tilde\Neff$ and GPS error: for larger error, more particles retain a high likelihood, and so the total weight is more evenly distributed. Conversely, larger values of system noise result in more variation between particles, which leads to fewer particles ending near the observation position.

<<model_performance_neff,echo=FALSE,message=FALSE,cache=TRUE,dependson="model_performance_prep",fig.width="8",fig.height=3,out.width="\\textwidth",fig.align="center",fig.cap="Proportional effective sample size for varying values of GPS error, system noise, and number of particles.">>=

res %>% filter(dist_to_path < 20 & dist_to_path > 0) %>%
    ggplot(aes(dist_to_path)) +
        geom_density() +
        xlab("Distance to path (m)") + ylab("Density") +
        theme_classic() +
        theme(strip.background = element_blank())

@




\begin{enumerate}
\item \emph{resampling rate}, which is how often the sample size falls below the threshold, which can be computed by $\frac{\Neff}{\Np}$;
\item \emph{degeneration rate}, the proportion of samples in which the vehicle was \emph{lost} by the particle filter (that is, no particles ended near the reported position); and
\item the \emph{relative variance} of segment travel times, which is a way to compare the variability of travel times along all segments across simulations (with differing parameter values).
\end{enumerate}

Beyond these general issues,
there were others that were particular to the \pf{},
or the data itself.
Regarding the \pf{},
we have already mentioned \emph{degeneration},
which is where the particle cloud becomes an inaccurate summarisation of vehicle state,
or in some cases loses the vehicle altogether (i.e., no particles near the observation).
This is controlled by
\begin{itemize}
\item increasing GPS error;
\item tuning system noise---too small and the vehicle is lost,
    too large and there's too much uncertainty; or
\item increasing the number of particles.
\end{itemize}
These are controlled by parameter selection,
discussed in \cref{sec:pf_params}.
However, there are other causes of degeneration caused by the data itself.


On of the major causes of \emph{vehicle loss}
is when the vehicle does not move for a long time.
This can be at a bus stop (although the model allows for this),
or, more commonly, at an unknown intersection.
However, it can also occur at choke points,
such as blocked bus lane in \emph{really really bad traffic},
so that the bus may be unable to move for several minutes.
In this situation,
we may get $\Vobs_k \approx \Vobs_{k-1}$ with large $\Vtdiff_k$,
so all possible trajectories from the model will place the vehicle
much farther down the route,
resulting in tiny likelihoods for all particles and
degeneration of the \pf{}.


Initially, we placed a tiny probability (0.01)
on the vehicle remaining stopped at its previous location,
so that a few particles remain stopped.
However,
this also led to poor estimation of travel times,
as inevitably all of the weight lands on a few particles.
Also, in some cases the bus \emph{will} move a little,
but far less than expected under the model.
An alternative would be to allow some of the particles to wait
for \emph{part of $\Vtdiff_k$}, and then travel,
but this led to different issues again.
It turns out that it is \emph{very hard to model a vehicle}
when the observations are sparse.


Before we discuss our solution,
we will refer back to \cref{sec:vp_data},
in which we mentioned the issue of \emph{preemtive} observations,
particularly at intersection waypoints,
and subsequent observations in the queue,
resulting in what appear to be a bus traveling backwards.
This has even more severe implications on the \pf{},
as our model explicitely states that
\emph{vehicles cannot travel backwards along the route}.
It would, therefore, seem that inspecting the data before modelling
would be advantageous.


True, the entire point of Bayes' filtering models is
to first predict the future state,
and \emph{then} update it using the observation.
However, in our case, there is so much variability in
where the future state might be,
that we have no choice but to examine the observation first,
and the decide best on how to model it.


So, we set up some checks of the observation to determine
if there are issues with the data we need to compensate for.
The simplest check is to compute the distance between consecutive observations
and check if it is below some threshold (e.g., 10~m)
$\dist{\Vobs_{k-1}, \Vobs_k} < \distThreshold$,
in which case we assume the vehicle hasn't moved.
Of course, this doesn't deal with reversing buses \ldots


To do this, we first need to detect if the observation is potentially
\emph{behind} the previous one.
That is,
\begin{equation}
\label{eq:vehicle_rev_check}
\Vmeas^{-1}(\Vobs_k) < \Vmeas^{-1}(\Vobs_{k-1}).
\end{equation}
If this occurs, we have several options:
\begin{itemize}
\item ignore the current observation,
    which is not favourable as, from observation of the data,
    it is more common for the first observation to be false
    (i.e., exactly at an intersection),
    followed by a more accurate one (in the queue approaching the intersection);
\item remove the previous observation and a backup of the previous state
    (i.e., we keep a backup of the vehicle's state before predicting and updating);
\item backup only each particle's weight,
    so that we can reset the weights prior to the previous observation,
    and allow only this new one to affect the reweighting.
    This means that we do not need to retransition all of the particles
    and store an entire state.
\end{itemize}

So now we briefly describe how these are implemented,
and show comparisons of how they handle!
Which involves finding a route where this happens every now and then,
and then run the (real) \pf{} on that data
to demonstrate the models.
Gosh, this will be finicky \ldots
