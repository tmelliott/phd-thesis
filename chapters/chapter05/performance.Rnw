\section{Real-time performance}
\label{sec:prediction_performance}

The real-time performance of the our application has always been the main bottleneck, in that it needs to run in real-time and provide arrival time predictions as soon as possible after the data is received.Â During the simulation run to obtain the results from \cref{sec:prediction_model_comparison}, we also recorded the timings of individual parts of the program, of which overall averages are displayed in \cref{tab:prediction_timing}. In it, we have two timers: wall clock and CPU clock. Wall clock is the real-world time passed, while CPU clock is the time spent on the processor. Since we are using only one core, these values are approximately similar, with the exception of the Load data step, which involves calling the \gls{gtfs} \gls{api} and waiting for the data to download. In steps where the CPU time and wall clock time are equal, then it is likely we can achieve significant speed gains by using more than a single core: using two cores would halve the time, and so on.


On average, the program takes less than 15~seconds, which is twice as fast as our initial target of 30~seconds. The most intensive component is updating of vehicle states, which involves updating 10,000 particles for each operating vehicle. This is followed by the \gls{eta} prediction step, which involves far fewer particles (we used 200 per trip), but each particle needs estimate more stops. However, the main advantage is that, in the vehicle update step, we need to perform a full weighted resample of the particles, which involves a lot of copying and sorting of objects within memory.

<<prediction_timing,echo=FALSE,message=FALSE,warning=FALSE,cache=F>>=
suppressPackageStartupMessages({
    library(tidyverse)
    library(knitr)
    library(kableExtra)
})
options(scipen = 10)

timings <- read_csv("data/timings.csv") %>% filter(iteration > 1)

tbl_times <- timings %>%
    group_by(what) %>%
    summarize(
        n = n(),
        wall_mean = mean(wall),
        wall_se = sd(wall) / sqrt(n),
        cpu_mean = mean(cpu),
        cpu_se = sd(cpu) / sqrt(n)
    ) %>%
    select(-n) %>%
    bind_rows(
    timings %>%
        group_by(iteration) %>%
        summarize(
            timestamp = first(timestamp),
            wall = sum(wall),
            cpu = sum(cpu)
        ) %>%
        ungroup() %>%
        summarize(
            what = "Total",
            n = n(),
            wall_mean = mean(wall),
            wall_se = sd(wall) / sqrt(n),
            cpu_mean = mean(cpu),
            cpu_se = sd(cpu) / sqrt(n)
        ) %>%
        select(-n)
    )


tbl_times <- tbl_times[c(1, 4, 5, 3, 2, 6, 7), ]
tbl_times <- tbl_times %>%
    mutate(
        wall_mean = format(signif(wall_mean, 3), drop0trailing = TRUE),
        wall_se = paste0("(", signif(wall_se, 2), ")"),
        cpu_mean = format(signif(cpu_mean, 3), drop0trailing = TRUE),
        cpu_se = paste0("(", signif(cpu_se, 2), ")")
    )
tbl_times$what <- c(
    "(L) Load data",
    "(U) Update vehicle information",
    "(V) Vehicle state update",
    "(N) Network state update",
    "(P) Predict ETAs",
    "(W) Write ETAs to protobuf feed",
    "(T) Total iteration time"
)
names(tbl_times) <- c("", "Wall clock", "(SE)", "CPU time", "(SE)")
kable(
    tbl_times,
    align = "lrlrl",
    booktabs = TRUE,
    caption = "Time taken during various parts of the program, running on a single core."
) %>%
    row_spec(6, extra_latex_after = "\\midrule")
@


However, there is huge variability in the number of buses operating at any given time, so in \cref{fig:prediction_timing_time} we have displayed the timings for each individual iteration over the course of the day. We again see the peak hour effect, where there are upwards of 1000~vehicles operating. This pushes the total iteration time to 30~seconds; however, again the two most intensive steps (vehicle update and \gls{eta} prediction) are thread-safe\footnote{At least, they are supposed to be\ldots currently a segfault occuring when running on multiple cores, not sure why.} and implemented to run on multiple cores, if available.


<<prediction_timing_time,warning=FALSE,echo=FALSE,cache=F,dependson=c(-1),fig.width=9,fig.height=4,out.width="\\textwidth",fig.cap="Timing results over time for various stages of the program: (L) Load data, (O) Update vehicles information, (V) Vehicle state update, (N) Network state update, (P) Predict ETAs, (W) Write ETAs to protobuf feed, (T) Total iteration time.">>=
# totals:
total_time <- timings %>%
    group_by(timestamp) %>%
    summarize(wall = sum(wall), cpu = sum(cpu), what = "total")
timings %>%
    bind_rows(total_time) %>%
    mutate(
        timestamp = as.POSIXct(timestamp, origin = "1970-01-01"),
        Stage = factor(what,
            levels = sort(unique(what))[c(1, 5, 6, 4, 2, 7, 3)],
            labels = c("L", "U", "V", "N", "P", "W", "T")
        )
    ) %>%
    arrange(timestamp) %>%
    ggplot(aes(timestamp)) +
        geom_path(aes(y = wall, colour = Stage, group = Stage)) +
        theme_classic() +
        xlab("Time") + ylab("Iteration timing (seconds, wall clock)")
@
