\subsection[Normal approximation]{Normal approximation (\Fnorm{})}
\label{sec:prediction_arrival_time_normal}

Due to the computational demand of the particle filter, significant speed improvements can be obtained by using a \normal{} approximation instead. The network state is a multivariate \normal{} random variable, so the issue lies with stop dwell times having a point mass at zero, resulting in a mixture predictive distribution. For each stop the vehicle passes, there are twice as many components, so after $m$ stops, there are $2^m$ components. However, these regularly converge after a few stops, as shown in \cref{fig:normal_approx}.

<<normal_approx,cache=TRUE,echo=FALSE,fig.width=8,fig.height=5,fig.cap="Normal approximation for 1, 2, 3, and 8 stops ahead. The full distribution is shown by the histogram with each components superimposed (dashed curves). The vertical lines represent the quantiles (2.5, 50, and 97.5\\%) computed using the samples (blue), the \\normal{} mixture (red), and a single \\normal{} approximation (green). The green curve is the single \\normal{} approximation.",out.width="\\textwidth",fig.align="center">>=
suppressPackageStartupMessages(library(tidyverse))
napprox <- function(n, pi = rep(0.8, n), t = c(80, 15),
                    mu = rep(20, n), sigma = rep(5, n)) {
    # indicator of stopping:
    d <- do.call(expand.grid, lapply(1:n, function(i) 0:1))
    pi <- apply(
        sapply(1:n, function(i) ifelse(d[,i], pi[i], 1 - pi[i])),
        1,
        prod
    )
    mu <- apply(
        sapply(1:n, function(i) t[1] + ifelse(d[,i], mu[i], 0)),
        1,
        sum
    )
    sigma <- sqrt(
        apply(
            sapply(1:n, function(i) t[2] + ifelse(d[,i], sigma[i]^2, 0)),
            1,
            sum
        )
    )

    daytah <- tibble(
        z = apply(rmultinom(1e6, 1, pi), 2, function(x) which(x == 1)),
        x = rnorm(1e6, mu[z], sigma[z])
    )

    px <- ggplot(daytah) +
        geom_histogram(aes(x, stat(density)), bins = 50, fill = "lightgray")

    xx <- seq(min(daytah$x), max(daytah$x), length = 1001)
    curves <- lapply(1:nrow(d),
        function(i) {
            geom_path(
                aes(x, y),
                data = tibble(
                    x = xx,
                    y = dnorm(xx, mu[i], sigma[i]) * pi[i]
                ),
                lty = 2
            )
        }
    )

    px <- Reduce("+", c(list(px), curves))

    ## Can we calculate the quantiles?
    q <- quantile(daytah$x, prob = c(0.05, 0.5, 0.95))
    px <- px +
        geom_vline(
            aes(colour = "Truth", xintercept = zzz),
            data = tibble(zzz = q),
            lwd = 1
        )

    f <- function(x, q = 0.95) {
        (sum(pi * pnorm(x, mu, sigma)) - q)^2
    }
    qq <- sapply(c(0.05, 0.5, 0.95),
        function(q) optimize(f, range(daytah$x), q = q)$minimum
    )
    px <- px +
        geom_vline(
            aes(colour = "Mixture", xintercept = zzz),
            data = tibble(zzz = qq),
            lty = 2
        )

    ## mean and var
    mean <- sum(pi * mu)

    EVarX <- sum(pi * sigma^2)
    VarEX <- sum(pi * mu^2) - sum(pi * mu)^2
    sd <- sqrt(EVarX + VarEX)

    px <- px +
        geom_path(
            aes(x, y, colour = "Single"),
            data = tibble(
                x = xx,
                y = dnorm(xx, mean, sd)
            )
        )

    ## Compare quantiles of single normal vs mixture
    qx <- qnorm(c(0.05, 0.5, 0.95), mean, sd)
    px <- px + geom_vline(
        aes(colour = "Single", xintercept = zzz), data = tibble(zzz = qx)
    )

    ## prettify the plot
    px <- px +
        theme_classic() +
        theme(plot.title = element_text(size = 10)) +
        scale_x_continuous(
            "ETA (minutes)",
            breaks = function(x) pretty(x / 60) * 60,
            labels = function(x) x / 60
        ) +
        scale_y_continuous("Probability density") +
        ggtitle(sprintf("%d stop%s", n, ifelse(n == 1, "", "s")))

    px
}

library(patchwork)

napprox(1, pi = 0.8, mu = 30, sigma = 20, t = c(30, 5)) +
    napprox(2, pi = c(0.8, 0.5),
        mu = c(30, 20), sigma = c(20, 10), t = c(70, 15)) +
    napprox(3, pi = c(0.5, 0.5, 0.5), mu = c(30, 20, 40),
        sigma = c(20, 10, 20), t = c(120, 20)) +
    napprox(8,
        pi = c(0.5, 0.5, 0.5, 0.5, 0.3, 0.5, 0.5, 0.5),
        mu = c(30, 20, 40, 20, 6, 20, 20, 20),
        sigma = c(20, 10, 20, 10, 5, 5, 5, 5),
        t = c(200, 40)
    ) +
    plot_layout(nrow = 2, guides = "collect") &
    theme(legend.position = "bottom") & labs(colour = "")
@

A mixture of \normal{} distributions can approximate the arrival time distribution \citep{Wang_2012} by expressing the mean and uncertainty as vectors $\tilde\mu$ and $\tilde\sigma^2$, respectively, along with a third vector $\tilde\pi$ denoting the $\tilde N$ mixture weights,\footnote{I place a tilde over parameters related to the \normal{} approximation, e.g., $\tilde x$, to help distinguish them from others used throughout the thesis.} such that
\begin{equation}
\label{eq:ch5:mixture_weight_spec}
\tilde\pi_i > 0, i = 1, \ldots, \tilde N
\text{ and } \sum_{i=1}^{\tilde N} \tilde\pi_i = 1.
\end{equation}
The arrival time at stop $j + n$ is then given by
\begin{equation}
\label{eq:arrival_time_normal_approx}
\Tarr_{j+n} | \tilde\mu, \tilde\sigma^2, \tilde\pi, \RouteNWstate =
\sum_{\ell=j}^{j+n-1} \RouteNWstateseg_\ell +
\sum_{i=1}^{\tilde N} \tilde\pi_i z_i,\quad
z_i \sim \Normal{\tilde\mu_i}{\tilde\sigma^2_i}.
\end{equation}


Each component $i$ has an indicator $I_{im} = \{0,1\}$ of whether it stopped at stop $m$, so the total dwell time has mean and variance
\begin{equation}
\label{eq:mixture_dwell_times}
\tilde\mu_i = \sum_{m=j}^{j+n} I_{im} \dwell_m\quad\text{and}\quad
\tilde\sigma_i^2 = \sum_{m=j}^{j+n} I_{im} \dwellvar_m,
\end{equation}
respectively, assuming dwell times at individual stops are independent of each other.

Mixture weights are obtained through the stopping probability at each stop, $\pi_j$:
\begin{equation}
\label{eq:ch5:mixture_weights}
\tilde\pi_i = \prod_{m=j}^{j+n} \tilde p_{im},
\end{equation}
where
\begin{equation}
\label{eq:ch5:mixture_weights2}
\tilde p_{im} =
\begin{cases}
\pi_m & \text{if } I_{im} = 1, \\
1 - \pi_m & \text{otherwise.}
\end{cases}
\end{equation}


The mixture approximation works well for a few stops ahead, but after some time the mixture weights become small, and the components combine, as shown in \cref{fig:normal_approx}. To prevent $\tilde N$ from becoming too large, the full distribution is simplified into a single component with mean
\begin{equation}
\label{eq:mixture_mean}
\begin{split}
\E{\Tarr_m | \tilde\pi, \tilde\mu, \tilde\sigma^2, \RouteNWstate} &=
\E{\sum_{\ell=j}^{j+n-1} \RouteNWstateseg_\ell +
  \sum_{i=1}^{\tilde N} \tilde\pi_i z_i} \\
&= \sum_{\ell=j}^{j+n-1} \E{\RouteNWstateseg_\ell} +
  \sum_{i=1}^{\tilde N} \tilde\pi_i \E{z_i} \\
&= \sum_{\ell=j}^{j+n-1} \hat\RouteNWstateseg_\ell +
  \sum_{i=1}^{\tilde N} \tilde\pi_i \tilde\mu_i
\end{split}
\end{equation}
and variance
\begin{equation}
\label{eq:mixture_variance}
\begin{split}
\Var{\Tarr_m | \tilde\pi, \tilde\mu, \tilde\sigma^2, \RouteNWstate} &=
\Var{\sum_{\ell=j}^{j+n-1} \RouteNWstateseg_\ell +
  \sum_{i=1}^{\tilde N} \tilde\pi_i z_i} \\
&= \sum_{\ell=j}^{j+n-1} \Var{\RouteNWstateseg_\ell} +
  \sum_{i=1}^{\tilde N} \tilde\pi_i^2 \Var{z_i} \\
&= \sum_{\ell=j}^{j+n-1} \hat\RouteNWstatevarseg_\ell +
  \sum_{i=1}^{\tilde N} \tilde\pi_i \tilde\sigma_i^2,
\end{split}
\end{equation}
assuming segment travel time and dwell time are independent---assuming otherwise makes this model impossible to work with. Indeed, this model versus the particle filter (which makes no such assumption) is effectively testing the viability of this assumption.


An optimisation is used to obtain quantiles $q_\alpha$ such that
\begin{equation}
\label{eq:mixture_quadratic}
\left[
  p\left(\alpha \leq \Tarr_m | \tilde\pi, \tilde\mu, \tilde\sigma^2, \RouteNWstate\right) - q_\alpha
\right]^2 = 0.
\end{equation}
This is straightforward using Brent's Algorithm \citep{Brent_1971}, implemented in the \pkg{Boost} \Cpp{} library.

When the 2.5\%, 50\%, and 97.5\% quantiles for the single approximation are within 30~seconds of the same quantiles computed for the mixture distribution, the mixture is replaced with one single component with mean and variance defined by \cref{eq:mixture_mean,eq:mixture_variance}. In some situations, the mixture may not converge into a single distribution quick enough, so to prevent the number of components $\tilde N$ from exceeding $2^8=256$, all components with weights less than a predefined threshold (we used $\frac{1}{2}\max_i(\tilde\pi_i)$) are combined into a single component.
