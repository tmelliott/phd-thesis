
\section{Estimating network parameters}
\label{sec:nw_par_est}


To use the \kf{} in any meaningful way, we first need to estimate the system noise, $\NWnoise_\ell$, and the between-vehicle variance, $\NWvar_{\ell}^2$. To estimate values for these parameters, we fit the same model from \cref{sec:nw_model} to the historical data shown in \cref{fig:tt_figure} using \gls{mcmc} sampling methods as implemented by \prog{JAGS} \citep{JAGS}.


The first step in the modelling process fits the following hierarchical model:
\begin{equation}
\label{eq:nw_model_simple}
\begin{split}
\Vttobs_{\ellc}^m &\sim \Normal{\Vtt_{\ellc}^m}{(\Vtterr_{\ellc}^m)^2}, \\
\Vtt_{\ellc}^m &\sim \TNormal{\NWstate_{\ellc}}{\NWvar_{\ell}^2}{0}{\MaxSpeed_\ell}, \\
\NWstate_{\ell,0} &\sim \Uniform{0}{\MaxSpeed_\ell}, \\
\NWstate_{\ellc} &\sim \TNormal{\NWstate_{\ell-1,c}}{(\NWtdiff_c \NWnoise_{\ell})^2}{0}{\MaxSpeed_\ell}, \\
\NWnoise_\ell &\sim \GammaD{0.01}{0.01}, \\
\NWvar_\ell &\sim \GammaD{0.01}{0.01}.
\end{split}
\end{equation}
The observation error, as in the previous section, is assumed to be constant for all observations, $\Vtterr_{\ellc}^m = 0.8$~\gls{mps} (which is about 10~km/h). The model implementation was performed from \Rstats{} using the \pkg{rjags} package \citep{rjags}. The model output was processed using the \pkg{tidybayes} package \citep{tidybayes} and graphed using \pkg{ggplot2} \citep{ggplot2}. The \pkg{coda} package was used to assess the model's convergence results \citep{coda}.


\subsection{Simulated data}
\label{nw_par_est_sim}

<<nw_model_sim_results,cache=TRUE,echo=FALSE,message=FALSE,fig.width=8,fig.height=5,out.width="0.8\\textwidth",fig.cap="Traceplots of model parameters for the simulated data. Each of the four chains are coloured separately. Dashed grey lines show the 95\\% posterior credible interval and the solid lines represent the true values or each parameter.",fig.align="center">>=
source("scripts/fit_sim_jags.R")
library(ggplot2)

ss <- sim_samples %>% spread_draws(q, phi)
ss_q <- ss %>% median_qi()
egg::ggarrange(
    ss %>% mutate(chain = as.factor(.chain)) %>%
        ggplot(aes(.iteration, q, colour = chain, group = chain)) +
            geom_path() +
            geom_hline(yintercept = simdata$pars$q) +
            geom_hline(yintercept = ss_q$q.lower, lty = 2, colour = "gray") +
            geom_hline(yintercept = ss_q$q.upper, lty = 2, colour = "gray") +
            theme_classic() +
            theme(legend.position = "none") +
            xlab("Iteration") +
            ylab(expression(q[l])),
    ss %>% mutate(chain = as.factor(.chain)) %>%
        ggplot(aes(.iteration, phi, colour = chain, group = chain)) +
            geom_path() +
            geom_hline(yintercept = simdata$pars$phi) +
            geom_hline(yintercept = ss_q$phi.lower, lty = 2, colour = "gray") +
            geom_hline(yintercept = ss_q$phi.upper, lty = 2, colour = "gray") +
            theme_classic() +
            theme(legend.position = "none") +
            xlab("Iteration") +
            ylab(expression(psi[l])),
    ncol = 1
)

@


To assess the model, we start by fitting it to the simulated data (\cref{fig:nw_sim_data}), for which we know the values of $\NWnoise_\ell$ and $\NWvar_\ell$. Trace plots of the model parameters shown in \cref{fig:nw_model_sim_results}, with the true values overlaid with a dashed line, show that the chains mixed well. \Cref{tab:nw_model_sim_smry} gives a summary of the simulation values and their posterior estimates, along with convergence statistics. The 95\% credible intervals for the two parameters contain the true values, so there is nothing to suggest the model is inadequate for modelling the simulated data and estimating the network parameters.


<<nw_model_sim_smry,echo=FALSE,results="asis",message=FALSE,cache=TRUE>>=
source("scripts/fit_sim_jags.R")
library(tibble)
smrytbl <- summary(sim_samples)
fmt0 <- function(x, s = 2) {
    # format each number to 2 signif
    sapply(x, function(z) as.character(signif(z, s)))
}
smry <- tibble(
    Parameter = c("$\\NWnoise_\\ell$", "$\\NWvar_\\ell$"),
    `True Value` = fmt0(as.numeric(simdata$pars[c("q", "phi")]), 1),
    `Mean` = fmt0(smrytbl$statistics[c("q", "phi"), "Mean"]),
    `2.5\\%` = fmt0(smrytbl$quantiles[c("q", "phi"), "2.5%"]),
    `50\\%` = fmt0(smrytbl$quantiles[c("q", "phi"), "50%"]),
    `97.5\\%` = fmt0(smrytbl$quantiles[c("q", "phi"), "97.5%"]),
    `$\\hat R$` =
        signif(coda::gelman.diag(sim_samples)$psrf[c("q", "phi"), 1], 4)
)
knitr::kable(smry,
    # digits = 3,
    booktabs = TRUE,
    caption = sprintf("MCMC results for the Bayesian model fitted to the simulated travel time data. The multivariate $\\hat R$, including for all of the $\\NWstate$ parameters, was %.2f, indicating that convergence had been achieved after 15,000 iterations.",
        coda::gelman.diag(sim_samples)$mpsrf
    ),
    caption.short = "MCMC results for the Bayesian model fitted to the simulated travel time data",
    escape = FALSE,
    valign = "b",
)
@



\subsection{Real data}
\label{nw_par_est_real}

<<nw_gelman,echo=FALSE,cache=TRUE,message=FALSE>>=
source("scripts/fit_nw_jags.R")
maxRhat <- ceiling(max(gelman.diag(n1_samples)$psrf[,2]) * 100) / 100
@

Having shown that the \prog{JAGS} model is a valid way of estimating the network parameters $\NWnoise_\ell$ and $\NWvar_\ell$, we model the real travel time data from \cref{fig:tt_figure}. Trace plots of the network parameters, as shown in \cref{fig:nw_model_n1_view}, show again that the chains mixed well, which is reaffirmed by the convergence results in \cref{tab:nw_model_fit_smry}. Not shown here are the summaries of the $\NWstate$'s (there are 187 of them); however, the Gelman diagnostic $\hat R$ was less than \Sexpr{maxRhat} for all of them, indicating they reached convergence.

<<nw_model_n1_view,cache=TRUE,message=FALSE,echo=FALSE,fig.height=5,fig.width=8,out.width="0.8\\linewidth",fig.cap="Traceplots of model parameters $\\NWnoise$ and $\\NWvar$ fitted to the segment data. Each of the four chains are coloured separately. The 95\\% posterior credible region is denoted by dashed grey lines.",fig.align="center",fig.scap="Traceplots of model parameters fitted to the segment data">>=
source("scripts/fit_nw_jags.R")
library(ggplot2)
n1_ss <- n1_samples %>% spread_draws(q, phi)
n1_ss_q <- n1_ss %>% median_qi()
egg::ggarrange(
    n1_ss %>% mutate(chain = as.factor(.chain)) %>%
        ggplot(aes(.iteration, q, colour = chain, group = chain)) +
            geom_path() +
            geom_hline(yintercept = n1_ss_q$q.lower, lty = 2, colour = "gray") +
            geom_hline(yintercept = n1_ss_q$q.upper, lty = 2, colour = "gray") +
            theme_classic() +
            theme(legend.position = "none") +
            xlab("Iteration") +
            ylab(expression(q[l])),
    n1_ss %>% mutate(Chain = as.factor(.chain)) %>%
        ggplot(aes(.iteration, phi, colour = Chain, group = Chain)) +
            geom_path() +
            geom_hline(
                yintercept = n1_ss_q$phi.lower, lty = 2, colour = "gray"
            ) +
            geom_hline(
                yintercept = n1_ss_q$phi.upper, lty = 2, colour = "gray"
            ) +
            theme_classic() +
            theme(legend.position = "none") +
            xlab("Iteration") +
            ylab(expression(psi[l])),
    ncol = 1
)
@

<<nw_model_fit_smry,echo=FALSE,results="asis",message=FALSE,cache=TRUE,cache.extra="file.info('models/nw_models.jags')">>=
source("scripts/fit_nw_jags.R")
library(tibble)

fmt0 <- function(x, s = c(2, 3)) {
    # format each number to 2 signif
    s <- rep(s, length.out = length(x))
    sapply(seq_along(x), function(i) as.character(signif(x[i], s[i])))
}
smrytbl <- summary(n1_samples)
smry <- tibble(
    Parameter = c("$\\NWnoise_\\ell$", "$\\NWvar_\\ell$"),
    `Mean` = fmt0(smrytbl$statistics[c("q", "phi"), "Mean"]),
    `2.5\\%` = fmt0(smrytbl$quantiles[c("q", "phi"), "2.5%"]),
    `50\\%` = fmt0(smrytbl$quantiles[c("q", "phi"), "50%"]),
    `97.5\\%` = fmt0(smrytbl$quantiles[c("q", "phi"), "97.5%"]),
    `$\\hat R$` =
        round(coda::gelman.diag(n1_samples)$psrf[c("q", "phi"), 1], 3)
)
knitr::kable(smry,
    # digits = 2,
    booktabs = TRUE,
    caption = sprintf("MCMC results for the Bayesian model fitted to the road segment travel time data. The multivariate $\\hat R$, including for all of the $\\NWstate$ parameters, was %.2f, indicating that convergence had been achieved after 15,000 iterations.",
        coda::gelman.diag(n1_samples)$mpsrf
    ),
    caption.short = "MCMC results for the Bayesian model fitted to the road segment travel time data",
    escape = FALSE,
    valign = "b",
)
@

To assess the adequacy of these parameters, we fit the \kf{} to the same data\footnote{In the next section we use two weeks of data, one for each of testing and training.} to see how well the mean and predictive distributions fit the data. The estimates of $\NWstate_{\ell,1:c}$, along with associated uncertainties, are shown in \cref{fig:nw_model_n1_kf1}, where we see that the mean approximately follows the center of the data. The predictive vehicle speed distribution, which accounts for both $\NWstatevar_{\ell,1:c}$ and vehicle variation, $\NWvar_{\ell}^2$, is shown in \cref{fig:nw_model_n1_kf2}, and shows most of the points contained within the 95\% posterior predictive region.


<<nw_model_n1_kf,cache=TRUE,echo=FALSE,message=FALSE,warning=FALSE,fig.width=6,fig.height=2,fig.align="center",out.width=".8\\textwidth",fig.cap="Results of fitting a \\kf{} to the segment data with parameters estimated using the hierarchical model.",fig.subcap=c('Estimated mean speed, showing state estimates along with the 95\\% credible region.', 'Predictive distribution of vehicle speeds, which includes between-vehicle variability.'),fig.ncol=1,fig.sep=rep("\\\\", 4)>>=
source("scripts/fit_nw_jags.R")
library(ggplot2)
N <- nrow(tts)
M <- length(unique(t30))
kf.fit <-
    tibble(
        time = sort(unique(t30)),
        delta = c(0, diff(sort(unique(t30)))),
        beta = rep(NA_real_, (M)),
        beta_hat = rep(NA_real_, (M)),
        P = rep(NA_real_, (M)),
        P_hat = rep(NA_real_, (M)),
        B_hat = 1 / P_hat,
        b_hat = beta_hat / P_hat,
        B = 1 / P,
        b = beta / P
    )

kf.fit$beta[1] <- n1_samples %>% spread_draws(beta[i]) %>%
    filter(i == 1) %>% median_qi() %>% pull(beta)
kf.fit$P[1] <- 50

q <- 30 * (n1_samples %>% spread_draws(q) %>% mean_qi() %>% pull(q))
phi <- n1_samples %>% spread_draws(phi) %>% mean_qi() %>% pull(phi)
mu <- 60 / 3.6


# convert all data to information
kf.data <-
    tibble(
        time = t30,
        t = as.integer(as.factor(t30)),
        b = tts$length / tts$travel_time,
        E = 0.2
    ) %>% mutate(
        I = 1 / (E^2 + phi^2),
        i = b / (E^2 + phi^2)
    ) %>% arrange(t)

kf.fit <- kf.fit %>%
    left_join(
        kf.data %>% group_by(t) %>%
            summarize(time = first(time), Z = sum(I), z = sum(i)),
        by = "time"
    )

t0 <- proc.time()
for (i in 2:M) {
    # predict
    kf.fit$beta_hat[i] <- kf.fit$beta[i-1]
    kf.fit$P_hat[i] <- kf.fit$P[i-1] + (kf.fit$delta[i] * q)^2

    # update
    kf.fit$B_hat[i] <- 1 / kf.fit$P_hat[i]
    kf.fit$b_hat[i] <- kf.fit$beta_hat[i] / kf.fit$P_hat[i]
    kf.fit$B[i] <- kf.fit$B_hat[i] + kf.fit$Z[i]
    kf.fit$b[i] <- kf.fit$b_hat[i] + kf.fit$z[i]

    # untransform
    kf.fit$beta[i] <- kf.fit$b[i] / kf.fit$B[i]
    kf.fit$P[i] <- 1 / kf.fit$B[i]
}
time_kf <- proc.time () - t0

library(ggplot2)

# ggplot(kf.data, aes(time, b)) + geom_point() +
#     geom_path(
#         aes(y = beta),
#         data = n1_samples %>%
#             spread_draws(beta[i]) %>%
#             mean_qi() %>%
#             mutate(time = unique(t30)[i]) %>%
#             arrange(time)
#     )

ggplot(kf.fit[-1,], aes(time)) +
    geom_point(aes(y = b), data = kf.data) +
    # geom_ribbon(aes(
    #         ymin = truncnorm::qtruncnorm(0.025, 0, mu, beta_hat, sqrt(P_hat)),
    #         ymax = truncnorm::qtruncnorm(0.975, 0, mu, beta_hat, sqrt(P_hat))
    #     ),
    #     fill = "blue", alpha = 0.2) +
    # geom_path(aes(y = beta_hat), col = "blue") +
    geom_ribbon(aes(
            ymin = truncnorm::qtruncnorm(0.025, 0, mu, beta, sqrt(P)),
            ymax = truncnorm::qtruncnorm(0.975, 0, mu, beta, sqrt(P))
        ),
        fill = "red", alpha = 0.2) +
    geom_path(aes(y = beta), col = "red") +
    theme_classic() +
    xlab("Time") + ylab("Speed (m/s)")

ggplot(kf.fit[-1,], aes(time)) +
    geom_point(aes(y = b), data = kf.data) +
    geom_ribbon(aes(
            ymin = truncnorm::qtruncnorm(0.025, 0, mu, beta, sqrt(P) + phi),
            ymax = truncnorm::qtruncnorm(0.975, 0, mu, beta, sqrt(P) + phi)
        ),
        fill = "blue", alpha = 0.2) +
    # geom_path(aes(y = beta), col = "blue") +
    theme_classic() +
    xlab("Time") + ylab("Speed (m/s)")
@



Finally, the timing comparison is displayed in \cref{tab:nw_model_n1_timecomp}. The hierarchical model fit using \prog{JAGS} took about \Sexpr{signif(time_mcmc[3] / time_kf[3], 2)} times as long as the \kf{} implementation. So, even if we reduced the number of chains, the number of iterations, and tried to speed up the \prog{JAGS} model, the \kf{} would still be significantly faster.


<<nw_model_n1_timecomp,cache=TRUE,echo=FALSE,results="asis">>=
source("scripts/fit_nw_jags.R")
library(ggplot2)
time_tab <- rbind(time_mcmc, time_kf)[,1:3]
dimnames(time_tab) <- list(
    c("JAGS", "Kalman filter"),
    c("User", "System", "Total")
)
kable(time_tab,
    booktabs = TRUE,
    caption = "Comparison of the timings for the MCMC and \\kf{} estimation methods. Times are reported in seconds.",
    caption.short = "Comparison of the timings for the MCMC and \\kf{} estimation methods",
    valign = "b"
)
@


\subsection{Hierarchical model over multiple road segments}
\label{sec:nw_par_est_multiple}

<<echo=FALSE,cache=FALSE,message=FALSE>>=
library(tidyverse)
wd <- setwd("../../data")
source("load_data.R")
setwd(wd)
con <- dbConnect(SQLite(), db)
Nseg <- con %>% tbl("road_segments") %>% tally() %>% collect() %>% pull("n")
@

To assess how effective our approach is for estimating $\NWvar_\ell$ and $\NWnoise_\ell$, we selected five other road segments around Auckland. However, instead of fitting the same model independently to each segment,  we use a hierarchical Bayesian model on the parameters, since it seems reasonable that, while they will not be the same for all segments, there will be an underlying population distribution. This allows us to obtain estimates of the parameter values without explicitly needing to model every road (of which there are \Sexpr{format(Nseg, big.mark=",")}).


The hierarchical model used to estimate the network parameters is:
\begin{equation}
\label{eq:tt_hist_hier}
\begin{split}
\Vttobs_{\ellc}^m &\sim \Normal{\Vtt_{\ellc}^m}{\left(\Vtterr_{\ellc}^m\right)^2}, \\
\Vtt_{\ellc}^m &\sim \TNormal{\NWstate_{\ellc}}{\NWvar_{\ell}^2}{0}{\MaxSpeed_\ell}, \\
\NWstate_{\ell0} &\sim \Normal{0}{10^2}, \\
\NWstate_{\ellc} &\sim \TNormal{\NWstate_{\ellc-1}}{(\NWtdiff_c \NWnoise_{\ell})^2}{0}{\MaxSpeed_\ell}, \\
q &\sim \GammaD{0.001}{0.001}, \\
\log\left(\NWvar_{\ell}\right) &\sim \Normal{\mu_\psi}{\sigma_\psi^2}, \\
\mu_\psi &\sim \Normal{0}{10^2}, \\
\sigma_\psi &\sim \GammaD{0.001}{0.001}.
\end{split}
\end{equation}
We initially attempted to fit a hierarchical segment noise parameter $\NWnoise_{\ell}$ with hyperparameters, but the values were all approximately equal for all segments and convergence was very slow (100,000's of iterations). Instead, we opted for a single common system noise parameter across all segments. The speed data for six segments on two consecutive Tuesdays is shown in \cref{fig:nw_model_n2_segplots}, with the locations of the roads displayed in \cref{fig:nw_seg_maps}.

<<nw_model_n2_segplots,echo=FALSE,cache=TRUE,fig.width=8,fig.height=9,out.width="\\textwidth",fig.cap="Observed average bus speeds along six road segments on two consecutive Tuesdays.",fig.align="center">>=
library(ggplot2)
source("scripts/load_nw_data.R")

date0 <- tt_all$arrival_time[1] %>% format("%Y-%m-%d")
bind_rows(tt_all, tt_future) %>%
    filter(segment_id %in% sids) %>%
    mutate(
        date = as.factor(format(arrival_time, "%Y-%m-%d")),
        time = as.POSIXct(paste(date0, format(arrival_time, "%H:%M:%S"))),
        l = as.integer(as.factor(segment_id)),
        speed = length / travel_time
    ) %>%
    ggplot() +
        geom_point(aes(time, speed)) +
        facet_grid(l ~ date, scales = "free") +
        scale_x_datetime(labels = function(x) format(x, "%H:%M:%S")) +
        theme_classic() +
        theme(strip.background = element_blank()) +
        xlab("Time") + ylab("Speed (m/s)")+
        scale_y_continuous(
            sec.axis = sec_axis(
                ~.*3.6,
                name = "Speed (km/h)"
            )
        )
@

<<nw_seg_maps,echo=FALSE,message=FALSE,cache=TRUE,fig.width=8,fig.height=12,out.width="\\textwidth",fig.cap="Segment locations, drawn using the \\pkg{ggmap} package \\citep{ggmap}. Segments begin at the solid point and terminate at the open point.",fig.align="center">>=
suppressPackageStartupMessages({
    library(ggplot2)
    library(ggmap)
    library(RSQLite)
    library(tidyverse)
    library(dbplyr)
})


source("scripts/load_nw_data.R")

con <- dbConnect(SQLite(), db)
nodes <- con %>% tbl("nodes") %>% select(node_id, node_lon, node_lat)
seg_locs <- con %>% tbl("road_segments") %>%
    left_join(nodes,
        by = c("node_from" = "node_id"),
        suffix = c("", "_from")
    ) %>%
    left_join(nodes,
        by = c("node_to" = "node_id"),
        suffix = c("", "_to")
    ) %>%
    filter(road_segment_id %in% !!sids) %>%
    collect()
# STOPS
stops <- con %>% tbl("stops") %>%
    filter(
        node_id %in% c(!!seg_locs$node_from, !!seg_locs$node_to) &
        version == 82.21
    ) %>% select(stop_id, node_id) %>% collect()
# BIND segs and stops
stop_segs <- seg_locs %>%
    left_join(
        stops,
        by = c("node_from" = "node_id"),
        suffix = c("", "_from")
    ) %>%
    left_join(
        stops,
        by = c("node_to" = "node_id"),
        suffix = c("", "_to")
    ) %>%
    rename(stop_id_from = stop_id) %>%
    select(road_segment_id, stop_id_from, stop_id_to) %>%
    rename(id = road_segment_id, from = stop_id_from, to = stop_id_to)
route_shapes <- pmap(stop_segs,
    function(id, from, to) {
        # find trips:
        tid <- con %>% tbl("stop_times") %>%
            filter(stop_id %in% c(!!from, !!to)) %>%
            group_by(trip_id) %>%
            tally() %>%
            filter(n == 2) %>%
            head(1) %>%
            pull(trip_id)
        sid <- con %>% tbl("trips") %>%
            filter(trip_id == tid) %>%
            select(shape_id) %>% pull(shape_id)
        S1 <- seg_locs %>% filter(road_segment_id == id) %>%
            select(node_lon, node_lat) %>% unlist()
        S2 <- seg_locs %>% filter(road_segment_id == id) %>%
            select(node_lon_to, node_lat_to) %>% unlist()
        shape <- con %>% tbl("shapes") %>%
            filter(shape_id == !!sid) %>%
            arrange(shape_pt_sequence) %>%
            select(shape_pt_lat, shape_pt_lon, shape_pt_sequence) %>%
            collect()
        sind <- shape %>%
            mutate(
                d1 = (shape_pt_lon - S1[1])^2 + (shape_pt_lat - S1[2])^2,
                d2 = (shape_pt_lon - S2[1])^2 + (shape_pt_lat - S2[2])^2,
                is_start = d1 == min(d1),
                is_end = d2 == min(d2)
            ) %>%
            filter(is_start | is_end) %>%
            summarize(
                start_index = min(shape_pt_sequence),
                stop_index = max(shape_pt_sequence)
            ) %>% unlist()
        shape[sind[1]:sind[2],] %>%
            mutate(segment_id = id)
    }
) %>% bind_rows()
dbDisconnect(con)

map_location <- function(data, zoom, id) {
    # adjust limits
    rad <- function(deg) deg * pi / 180
    deg <- function(rad) rad * 180 / pi
    R <- 6378137
    xlim <- sort(c(data$node_lon, data$node_lon_to))
    ylim <- sort(c(data$node_lat, data$node_lat_to))
    xl <- diff(rad(xlim)) * cos(mean(rad(ylim))) * R
    yl <- diff(rad(ylim)) * R

    sqr_w <- max(xl, yl) * 2
    xw <- deg(sqr_w / R / cos(mean(rad(ylim))))
    yw <- deg(sqr_w / R)

    bbox <- c(
        mean(xlim) - xw / 2,
        mean(ylim) - yw / 2,
        mean(xlim) + yw / 2,
        mean(ylim) + yw / 2
    )
    m <- get_stamenmap(bbox, zoom = zoom)

    ggmap(m) +
        geom_path(
            aes(
                x = shape_pt_lon,
                y = shape_pt_lat
            ),
            data = route_shapes %>% filter(segment_id == data$road_segment_id),
            size = 1.5
        ) +
        geom_point(aes(node_lon, node_lat), data = data, stroke = 2) +
        geom_point(aes(node_lon_to, node_lat_to), data = data,
            shape = 21, fill = "white", stroke = 2) +
        theme_minimal() +
        theme(
            axis.text = element_blank(),
            plot.title = element_text(size = 10)
        ) +
        ggtitle(paste("Segment", id)) +
        xlab("") + ylab("")
}

zoom <- c(16, 16, 12, 14, 16, 16)
maps <- lapply(
    seq_len(nrow(seg_locs)),
    function(i) map_location(seg_locs[i, ], zoom = zoom[i], i)
)
do.call(egg::ggarrange, c(maps, list(nrow = 3)))
@


<<nw_model_nw_jagsfits,echo=FALSE,cache=TRUE,message=FALSE>>=
source("scripts/load_nw_data.R")
suppressPackageStartupMessages({
    library(dplyr)
    library(rjags)
    library(tidybayes)
    library(ggplot2)
})
nwsfile <- "data/hier_model_samples.rda"
if (!file.exists(nwsfile)) {
    model.jags <- "
    model{
        for (i in 1:N) {
            b[i] ~ dnorm(B[i], pow(e[i], -2))
            B[i] ~ dnorm(beta[c[i]], pow(phi[ell[i]], -2))T(0, mu[ell[i]])
        }

        for (l in 1:L) {
            beta[c0[l]] ~ dunif(0, mu[l])
            for (j in c1[l]:cJ[l]) {
                beta[j] ~ dnorm(beta[j-1], pow(delta[j] * q, -2))T(0, mu[l])
            }

            phi[l] <- exp(log_phi[l])
            log_phi[l] ~ dnorm(mu_phi, pow(sig_phi, -2))

            #q[l] ~ dnorm(mu_q, pow(sig_q, -2))T(0,)
        }

        mu_phi ~ dnorm(0, 0.01)
        sig_phi ~ dgamma(0.0001, 0.0001)

        q ~ dgamma(0.0001, 0.0001)
        #mu_q <- exp(log_mu_q)
        #log_mu_q ~ dnorm(0, 0.01)
        #sig_q ~ dgamma(0.001, 0.001)
    }
    "

    jm <-
        jags.model(textConnection(model.jags),
            quiet = TRUE,
            data = jdata,
            n.chains = 4,
            n.adapt = 100000
        )

    n1_samples <-
        coda.samples(jm,
            variable.names =
                c("beta", "phi", "mu_phi", "sig_phi", "q"),
            n.iter = 50000,
            thin = 50
        )

    save(n1_samples, file = nwsfile)
} else {
    load(nwsfile)
}
@

<<nw_model_n2_diag,cache=TRUE,message=FALSE,echo=FALSE,fig.width=8,fig.height=6,out.width="\\textwidth",fig.cap="Traceplots of top-level network parameters estimated by the hierarhical model. The four chains are coloured individually, and 95\\% credible interval indicated by dashed gray lines.",fig.align="center">>=
source("scripts/load_nw_data.R")
load("data/hier_model_samples.rda")

ss <- n1_samples %>% spread_draws(mu_phi, sig_phi, q)
ss_q <- ss %>% median_qi()
pmin <-
    ggplot(ss,
        aes(x = .iteration, colour = as.factor(.chain), group = .chain)
    ) +
    xlab("Iteration") +
    theme_classic() +
    theme(legend.position = "none")


egg::ggarrange(
    pmin +
        geom_path(aes(y = mu_phi)) +
        geom_hline(yintercept = ss_q$mu_phi.lower,
            lty = 2, colour = "gray") +
        geom_hline(yintercept = ss_q$mu_phi.upper,
            lty = 2, colour = "gray") +
        ylab(expression(mu[phi])),
    pmin +
        geom_path(aes(y = sig_phi)) +
        geom_hline(yintercept = ss_q$sig_phi.lower,
            lty = 2, colour = "gray") +
        geom_hline(yintercept = ss_q$sig_phi.upper,
            lty = 2, colour = "gray") +
        ylab(expression(sigma[psi])),
    pmin +
        geom_path(aes(y = q)) +
        geom_hline(yintercept = ss_q$q.lower,
            lty = 2, colour = "gray") +
        geom_hline(yintercept = ss_q$q.upper,
            lty = 2, colour = "gray") +
        ylab(expression(q)),
    ncol = 1, byrow = FALSE
)
@


<<nw_model_n2_smry,cache=TRUE,echo=FALSE,results="asis">>=
load("data/hier_model_samples.rda")
library(tibble)
smry <- summary(n1_samples)
gd <- coda::gelman.diag(n1_samples)
vn <- c("mu_phi", "sig_phi", "q")#, "mu_q", "sig_q")

fmt0 <- function(x, s = c(3, 3, 2)) {
    # format each number to 2 signif
    s <- rep(s, length.out = length(x))
    sapply(seq_along(x), function(i) as.character(signif(x[i], s[i])))
}

restbl <-
    tibble(
        Parameter = c("$\\mu_\\psi$", "$\\sigma_\\psi$", "$q$"),
                      #"\\mu_q", "\\sigma_q"),
        Mean = fmt0(smry$statistics[vn, "Mean"]),
        `2.5\\%` = fmt0(smry$quantiles[vn, "2.5%"]),
        `50\\%` = fmt0(smry$quantiles[vn, "50%"]),
        `97.5\\%` = fmt0(smry$quantiles[vn, "97.5%"]),
        `$\\hat R$` = gd$psrf[vn, 1]
    )
knitr::kable(restbl,
    digits = 2,
    booktabs = TRUE,
    caption = sprintf("MCMC results for the hierarchical Bayesian model fitted to six road segments to estimate the top-level variance parameters. The multivariate $\\hat R$, including for all of the $\\NWstate$ parameters, was %.2f.",
        gd$mpsrf
    ),
    caption.short = "MCMC results for the hierarchical Bayesian model fitted to six road segments to estimate the top-level variance parameters",
    escape = FALSE,
    valign = "b",
)
@


The model was fit using \prog{JAGS} to the first day of data for the six segments, while the second was reserved for testing the validity of the estimated parameters. Each of the four chains was run with a 100,000~iteration burn-in phase, followed by 50,000 iterations with a thinning interval of 50. Trace plots of the top-level parameters are displayed in \cref{fig:nw_model_n2_diag}, which demonstrates good mixing of the chains. \Cref{tab:nw_model_n2_smry} shows the posterior mean and quantiles for these parameters, along with their Gelman convergence diagnostics.


Trace plots for the segment-specific variance parameters are shown in \cref{fig:nw_model_n2_diag_2}, and also demonstrate good mixing. The Gelman convergence diagnostic is again very close to unity, indicating that running the chain for longer would not decrease the posterior variance by much.



<<nw_model_n2_diag_2,cache=TRUE,echo=FALSE,fig.width=8,fig.height=5,out.width="\\textwidth",fig.cap="Traceplots of between-vehicle variance parameters, $\\NWvar_\\ell$, for each segment. The four chains are coloured individually.",fig.align="center">>=
source("scripts/load_nw_data.R")
load("data/hier_model_samples.rda")

pmin <- ggplot(NULL, aes(x = .iteration, colour = as.factor(.chain), group = .chain)) +
    xlab("Iteration") +
    theme_classic() +
    theme(legend.position = "none", strip.background = element_blank())
# egg::ggarrange(
    pmin +
        geom_path(aes(y = phi),
            data = n1_samples %>% spread_draws(phi[l])
        ) +
        ylab(expression(psi[l])) +
        facet_wrap(l~., scales = "free_y", ncol = 2)
    #pmin +
    #    geom_path(aes(y = q),
    #        data = n1_samples %>% spread_draws(q[l])
    #    ) +
    #    ylab(expression(q[l])) +
    #    facet_wrap(l~., scales = "free_y", ncol = 1),
#    ncol = 1
#)
@


The \kf{} was fit to each segment using the posterior mean of $\NWvar_\ell$ and the population parameters. \Cref{fig:nw_model_n2_kf} shows the original data superimposed with a posterior sample of $\NWstate$'s, along with the next week's data with results from the \kf{}, including the 95\% credible region for the mean travel time and the 95\% posterior predictive region for individual vehicle travel times.





<<nw_model_n2_kf_fit,echo=FALSE,cache=TRUE>>=
library(ggplot2)
library(tidybayes)
source("scripts/load_nw_data.R")
load("data/hier_model_samples.rda")


kf_fits <- lapply(seq_along(sids), function(l) {
    sid <- sort(sids)[l]
    tts <- tt_future %>% filter(segment_id == !!sid)
    t30 <- paste(sep = ":",
        format(tts$arrival_time,
            "%Y-%m-%d %H"),
        format(tts$arrival_time, "%M") %>%
            as.integer %>% `%/%`(5) %>% `*`(5) %>%
            stringr::str_pad(2, pad = "0")
    ) %>% as.POSIXct

    N <- nrow(tts)
    M <- length(unique(t30))
    kf.fit <-
        tibble(
            time = sort(unique(t30)),
            delta = c(0, diff(sort(unique(t30)))),
            beta = rep(NA_real_, (M)),
            beta_hat = rep(NA_real_, (M)),
            P = rep(NA_real_, (M)),
            P_hat = rep(NA_real_, (M)),
            B_hat = 1 / P_hat,
            b_hat = beta_hat / P_hat,
            B = 1 / P,
            b = beta / P
        )


    kf.fit$beta[1] <- median(tts$length / tts$travel_time)
    kf.fit$P[1] <- 5

    q_phi <- n1_samples %>% spread_draws(q, phi[l]) %>%
        filter(l == !!l) %>% median_qi()
    q <- 30 * q_phi$q
    phi <- q_phi$phi
    mu <- jdata$mu[l]

    # convert all data to information
    kf.data <-
        tibble(
            time = t30,
            t = as.integer(as.factor(t30)),
            b = tts$length / tts$travel_time,
            E = 0.8
        ) %>% mutate(
            I = 1 / (E^2 + phi^2),
            i = b / (E^2 + phi^2)
        ) %>% arrange(t)

    kf.fit <- kf.fit %>%
        left_join(
            kf.data %>% group_by(t) %>%
                summarize(time = first(time), Z = sum(I), z = sum(i)),
            by = "time"
        )

    for (i in 2:M) {
        # predict
        kf.fit$beta_hat[i] <- kf.fit$beta[i-1]
        kf.fit$P_hat[i] <- kf.fit$P[i-1] + (kf.fit$delta[i] * q)^2

        # update
        kf.fit$B_hat[i] <- 1 / kf.fit$P_hat[i]
        kf.fit$b_hat[i] <- kf.fit$beta_hat[i] / kf.fit$P_hat[i]
        kf.fit$B[i] <- kf.fit$B_hat[i] + kf.fit$Z[i]
        kf.fit$b[i] <- kf.fit$b_hat[i] + kf.fit$z[i]

        # untransform
        kf.fit$beta[i] <- kf.fit$b[i] / kf.fit$B[i]
        kf.fit$P[i] <- 1 / kf.fit$B[i]
    }

    kf.fit %>% mutate(segment_id = sid, mu = mu, q = q, phi = phi)
}) %>% bind_rows



betas <- n1_samples %>% spread_draws(beta[i]) %>%
    sample_draws(n = 20) %>%
    # median_qi() %>%
    mutate(
        l = tapply(jdata$ell, jdata$c, min)[i],
        t = jdata_t[i],
        mu = jdata$mu[l]
    )

speed_trans <- scales::trans_new(
    "speed",
    function(x) x*3.6,
    function(x) x/3.6
)

@

<<nw_model_n2_kf,echo=FALSE,cache=TRUE,dependson="nw_model_n2_kf_fit",fig.width=8,fig.height=7,out.width="\\textwidth",fig.cap="Results for the hierarchical approach to modelling road speed. Left: the training data with a sample of posterior fits for \\prog{JAGS}. Right: the test data with the Kalman filter estimation results, showing the speed estimate (red line), its uncertainty (shaded in red), and the posterior predictive region for vehicle speeds (shaded in grey).">>=
egg::ggarrange(
    ggplot(betas %>% mutate(l = paste("Segment", l))) +
        geom_point(aes(timestamp, length / travel_time),
            data = segdat %>% mutate(l = paste("Segment", l)),
            colour = "black", size = 0.5) +
        geom_path(aes(t, beta, group = .draw),
            colour = "red", alpha = 0.5) +
        facet_wrap(~l, ncol = 1) +
        theme_classic() +
        theme(strip.background = element_blank()) +
        ylim(0, 20) +
        xlab("Time") + ylab("Speed (m/s)"),

    kf_fits %>%
        mutate(
            l = paste("Segment", as.integer(as.factor(segment_id)))
        ) %>%
    ggplot(aes(time)) +
        facet_wrap(~l, ncol = 1) +
        geom_point(aes(arrival_time, y = length / travel_time),
            data = tt_future %>% filter(segment_id %in% sids) %>%
                mutate(
                    l = paste("Segment", as.integer(as.factor(segment_id)))
                ),
        ) +
        geom_ribbon(aes(
                ymin = truncnorm::qtruncnorm(0.025, 0, mu, beta, sqrt(P) + phi),
                ymax = truncnorm::qtruncnorm(0.975, 0, mu, beta, sqrt(P) + phi)
            ),
            fill = "black", alpha = 0.2) +
        geom_ribbon(aes(
                ymin = truncnorm::qtruncnorm(0.025, 0, mu, beta, sqrt(P)),
                ymax = truncnorm::qtruncnorm(0.975, 0, mu, beta, sqrt(P))
            ),
            fill = "red", alpha = 0.2) +
        geom_path(aes(y = beta), col = "red") +
        theme_classic() +
        theme(strip.background = element_blank()) +
        ylim(0, 20) +
        xlab("Time") + ylab("Speed (m/s)"),
    ncol = 2
)
@

The results show that the $\NWstate$ values estimated with \prog{JAGS} nicely fit the data, including peak congestion, as do the \kf{} estimates. The posterior predictive region covers most of the observations for all the segments.
