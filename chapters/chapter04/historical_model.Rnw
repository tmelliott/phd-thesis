\section{Improving forecasts with history}
\label{sec:nw_hist_model}

The model presented in \cref{sec:nw_model,sec:nw_realtime,sec:nw_par_est} is adequate for estimating the \emph{real-time} state of the network, but is unuseful for forecasting vehicle speeds, particularly just before or after a peak period. In \cref{cha:prediction}, we explore the prediction of arrival times, which involves making short-term forecasts of speed. Using historical data is one way of improving speed forecasts, particularly around peak times.


In \cref{nw_par_est_real}, I showed that most roads have a ``peak effect'' in the morning or the evening, while some exhibit both. It seems reasonable therefore to have a model which allows a segment to have zero, one, or two peaks, each with varying magnitude (the size of the decrease in speed) and width (how long the peak period is). The temporal location of these peaks is likely to be related, but variable: some roads will experience peak traffic earlier than others, for example.

<<tt_week0_load,cache=TRUE,echo=FALSE,fig.height=8,fig.width=8,fig.align="center",out.width="\\textwidth",fig.cap="Vehicle speeds along six road segments over one week, coloured by the day of the week.",fig.scap="Vehicle speeds along six road segments over one week">>=
library(ggplot2)
source("scripts/load_week_data.R")

data_week0 %>% filter(segment_id %in% sids) %>%
    mutate(weekday = factor(
        ifelse(dow %in% c("Saturday", "Sunday"), "weekend", "weekday")
    )) %>%
    # filter(!dow %in% c("Saturday", "Sunday")) %>%
    ggplot(aes(time, length / travel_time, colour = dow)) +
        geom_point() +
        # geom_smooth(aes(colour = NULL),span = 0.2) +
        scale_x_datetime(labels = function(t) format(t, "%l%P")) +
        facet_grid(segment_id~weekday, scales = "free_y") +
        theme_classic() +
        theme(strip.background = element_blank(), legend.position = "bottom") +
        xlab("Time") + ylab("Speed (m/s)") +
        scale_colour_brewer(palette = "Dark2") +
        labs(colour = "Day of week")

@

Early work fitting Bayesian models to these data were not promising, as it involved too much manual work tuning the parameters for each segment and checking the results. Since our goal is to obtain a generalised framework that runs with minimal manual effort, we sought an alternative.

From \cref{fig:tt_week0_load} it is clear that along each segment, there is a consistent pattern, with some variability between days as far as the temporal location and magnitude of the ``peak'' on weekdays; weekends are fairly consistent, although this is only two days' worth of data. Here I present a nearest-neighbour grid, which takes time and road state (traffic speed) as input, and outputs the mean (and uncertainty) of travel time in 10, 20, or 30~minutes from the current time. Similar ``speed maps'' have been used by the likes of \citet{Cathey_2003, Celan_2017, Chen_2014}. The first step is to aggregate observations into 5~minute intervals and take the mean traffic speed in each interval. Next, we bind lagged duplicates of these speeds (10, 20, 30~minutes, for example), such that each row includes current and future states. Any missing periods are interpolated from the mean of the adjacent states. The speed map for 30~minute predictions is shown in \cref{fig:tt_week0_grid}. The lighter areas represent higher speeds.


<<tt_week0_grid_fit,cache=TRUE,echo=FALSE>>=
library(ggplot2)
source("scripts/load_week_data.R")
library(FNN)

seg_fits <-
    lapply(sids, function(sid) {
        week0_smry <- data_week0 %>%
            filter(segment_id == sid) %>%
            mutate(
                weekday = factor(
                    ifelse(dow %in% c("Saturday", "Sunday"), "weekend", "weekday")
                ),
                t_int = as.integer(format(time, "%H")) +
                    5 * (as.integer(format(time, "%M")) %/% 5) / 60
            ) %>%
            group_by(t_int, date) %>%
            summarise(
                mean = mean(length / travel_time),
                e = sd(length / travel_time),
                weekday = first(weekday)
            ) %>%
            ungroup() %>%
            mutate(time_30 = t_int + 30/60)

        week0_smry <- week0_smry %>%
            left_join(
                week0_smry %>% select(t_int, date, mean) %>%
                    rename(tt30 = mean),
                by = c("date", "time_30" = "t_int")
            ) %>%
            group_by(date) %>%
            do({
                w0 <- (.) %>% arrange(t_int)
                for (i in which(is.na(w0$tt30))) {
                    if (i == 1) {
                        w0$tt30[1] <- w0 %>% filter(!is.na(tt30)) %>% pull(tt30) %>% head(1)
                    } else {
                        w0$tt30[i] <- mean(w0$tt30[c(i-1, i+1)], na.rm = TRUE)
                    }
                }
                w0
            }) %>% ungroup()

        week0_train <- week0_smry %>%
            filter(weekday == "weekday") %>%
            select(t_int, mean, tt30) %>%
            filter(!is.na(tt30))

        weekX_test <- with(week0_train,
            expand.grid(
                # every 5 mins
                t_int = seq(5, 24, by = 5/60),
                mean = seq(min(mean), max(mean), length = 100)
            )
        ) %>% as_tibble

        fit <- knn.reg(week0_train %>% select(-tt30) %>% scale(),
            weekX_test %>% scale(), y = week0_train %>% pull(tt30),
            k = 10
        )
        weekX_test %>% as_tibble() %>%
            mutate(pred = fit$pred, segment_id = sid)
    }) %>% bind_rows
save(seg_fits, file = "data/seg_fits.rda")
@




<<tt_week0_grid,cache=TRUE,echo=FALSE,message=FALSE,warning=FALSE,fig.height=10,fig.width=8,fig.align="center",out.width="\\linewidth",fig.cap="Speed maps to predict segment speed in 30~minutes given the current average speed (y-axis) and time (x-axis).",fig.scap="Speed maps to predict segment speed in 30~minutes given the current state">>=
library(ggplot2)
library(tidyverse)
load("data/seg_fits.rda")

sids <- unique(seg_fits$segment_id)
do.call(egg::ggarrange,
    c(
        lapply(seq_along(sids), function(l) {
            sid <- sids[l]
            seg_fits %>% filter(segment_id == sid) %>%
                ggplot(aes(t_int, mean, z = pred)) +
                    geom_raster(aes(fill = pred), interpolate = TRUE) +
                    scale_fill_viridis_c(option = "A") +
                    scale_x_continuous(expand = c(0, 0)) +
                    scale_y_continuous(expand = c(0, 0)) +
                    theme_classic() +
                    # geom_contour(colour = "black") +
                    # scale_colour_viridis_c() +
                    labs(fill = "Prediction") +
                    xlab("Time t") + ylab("Road state (m/s)")
        }),
        list(ncol = 1)
    )
)

# seg_fits %>% group_by(segment_id) %>%
#     do({
#         fit <- (.)
#         vc <- viridis::viridis(
#             max(round(fit$pred)) - min(round(fit$pred)) + 1,
#             option = "A"
#         )
#         fit %>% mutate(col = vc[pred-min(pred)+1])
#     }) %>%
#     ggplot(aes(t_int, mean)) +
#         geom_raster(aes(fill = I(col)), interpolate = TRUE) +
#         scale_x_continuous(expand = c(0, 0)) +
#         scale_y_continuous(expand = c(0, 0)) +
#         facet_grid(segment_id~., scales = "free_y") +
#         theme_classic() +
#         theme(legend.position = "none") +
#         xlab("Time t") + ylab("Road state (seconds)")
@

The next step is to evaluate the predictive power of this approach. We do this by taking the second week of data (shown in \cref{fig:tt_week1_load}) and use the fitted estimates to predict the state in 30~minutes, and then compare this to the actual state in 30~minutes. The \gls{rmse} (\cref{app:error-functions}) is used to compare the predicted and observed speeds.



<<tt_week1_load,cache=TRUE,echo=FALSE,message=FALSE,warning=FALSE,fig.height=8,fig.width=8,fig.align="center",out.width="\\linewidth",fig.cap="Vehicle speeds along six roads over the course of two weeks, showing only week days, for training (left) and testing (right).",fig.scap="Vehicle speeds along six roads over of two weeks.">>=
library(ggplot2)
source("scripts/load_week_data.R")
load("data/seg_fits.rda")

bind_rows(
    data_week0 %>% mutate(week = "week 1"),
    data_week1 %>% mutate(week = "week 2")
) %>%
    filter(segment_id %in% sids) %>%
    filter(!dow %in% c("Saturday", "Sunday")) %>%
    ggplot(aes(time, length / travel_time, colour = dow)) +
        geom_point() +
        scale_x_datetime(labels = function(t) format(t, "%l%P")) +
        facet_grid(segment_id~week, scales = "free_y") +
        theme_classic() +
        theme(strip.background = element_blank(), legend.position = "bottom") +
        xlab("Time") + ylab("Speed (m/s)") +
        scale_colour_brewer(palette = "Dark2") +
        labs(colour = "Day of week")

@

<<tt_week1_pred,cache=TRUE,message=FALSE,warning=FALSE,echo=FALSE,fig.height=8,fig.width=8,fig.align="center",out.width="\\linewidth",fig.cap="Forecasts of average vehicle speeds in 30 minutes versus actual average speed in 30 minutes along segments. The line of equality (red) indicates a perfect prediction. The closer the best fit line (blue) is to the line of equality, the better the forecasts.">>=
suppressPackageStartupMessages({
    library(ggplot2)
    library(purrr)
})
source("scripts/load_week_data.R")
load("data/seg_fits.rda")

seg_preds <-
    lapply(sids, function(sid) {
        week1_smry <- data_week1 %>%
            filter(segment_id == sid) %>%
            mutate(
                weekday = factor(
                    ifelse(dow %in% c("Saturday", "Sunday"), "weekend", "weekday")
                ),
                t_int = as.integer(format(time, "%H")) +
                    5 * (as.integer(format(time, "%M")) %/% 5) / 60
            ) %>%
            filter(weekday == "weekday") %>%
            group_by(t_int, date) %>%
            summarise(
                    mean = mean(length / travel_time),
                    e = sd(length / travel_time),
                    weekday = first(weekday)
                ) %>%
            ungroup() %>%
            mutate(time_30 = t_int + 30/60)

        week1_smry <- week1_smry %>%
            left_join(week1_smry %>% select(t_int, date, mean) %>%
                rename(tt30 = mean),
                by = c("date", "time_30" = "t_int")
            ) %>%
            mutate(segment_id = sid)

        week1_smry %>% select(segment_id, date, t_int, mean, e, tt30)
    }) %>% bind_rows %>% group_by(segment_id) %>%
    do({
        seg_x <- (.)
        cv <- seg_fits %>%
            filter(segment_id == seg_x$segment_id[1]) %>%
            pull(mean) %>% unique()
        seg_x %>% mutate(
            mean_original = mean,
            mean = cut(seg_x$mean, c(0, cv, Inf),
                labels = c(cv[1], cv), right = FALSE) %>%
                as.character() %>% as.numeric %>% round(1)
        )
    }) %>%
    left_join(seg_fits %>% mutate(mean = round(mean, 1)),
        by = c("segment_id", "t_int", "mean")) %>%
    filter(!is.na(tt30) & !is.na(pred) & !is.na(mean_original))

egg::ggarrange(
    ggplot(seg_preds, aes(pred, tt30, colour = NULL)) +
        geom_point(colour = "gray20") +
        geom_smooth(aes(colour = NULL), method="lm") +
        facet_wrap(segment_id~., scales = "free", ncol = 1) +
        # scale_colour_brewer(palette = "Dark2") +
        # scale_colour_viridis_c() +
        xlab("Speed orecast (m/s)") +
        ylab("Observed speed (m/s)") +
        theme_classic() +
        theme(legend.position = "none", strip.background = element_blank()) +
        geom_abline(slope = 1, intercept = 0, colour = "orangered"),
    ggplot(seg_preds, aes(mean_original, tt30, colour = NULL)) +
        geom_point(colour = "gray20") +
        geom_smooth(aes(colour = NULL), method="lm") +
        facet_wrap(segment_id~., scales = "free", ncol = 1) +
        # scale_colour_brewer(palette = "Dark2") +
        # scale_colour_viridis_c() +
        xlab("Speed orecast (m/s)") +
        ylab("Observed speed (m/s)") +
        theme_classic() +
        theme(strip.background = element_blank()) +
        geom_abline(slope = 1, intercept = 0, colour = "orangered"),
    ncol = 2
)

RMSE_forecast <- sqrt(mean(with(seg_preds, pred - tt30)^2, na.rm = TRUE))
RMSE_equal <- sqrt(mean(with(seg_preds, mean_original - tt30)^2, na.rm = TRUE))
@


Forecasts 30~minutes into the future are shown in \cref{fig:tt_week1_pred} for both the grid-search method, as well as the na\"ive method of using the current average traffic speed as the predictor. The comparative \gls{rmse} values are displayed in \cref{tab:tt_pred_rmse}. However, these are not too different because there is a lot of inherent uncertainty, but demonstrate a slight increase in predictive performance when historical trends are used.


Most importantly, however, is the linear curve (shown in blue in \cref{fig:tt_week1_pred}) compared to the line of equality, in red. The interpretation is that the more accurate the predictions on average, the closer the blue trend line will be to the black line of equality. For our forecast model, we see that in 5 out of 6 segments the two lines are very close, compared to the na\"ive estimate in which case the predictions are often too high or too low.


Further work is needed to improve the forecasting abilities of our model. However, we have designed the framework in such a way that any such improvements can easily be integrated into both the network modelling stage, and the upcoming arrival time prediction stage (see \cref{sec:nw_implementation_forecast} for details).

<<tt_pred_rmse,echo=FALSE,results="asis",cache=TRUE>>=

kable(
    tibble(
        Method = c("Simple", "Forecast"),
        `RMSE (m/s)` = round(c(RMSE_equal, RMSE_forecast), 2)
    ),
    booktabs = TRUE,
    caption = "RMSE results comparing the predictive performance of two forecast methods for predicting road state in 30~minutes."
)
@
