\section{\Rt{} network model}
\label{sec:nw_realtime}

For a real-time application, time is the number one constraint. Therefore, we begin by presenting a Kalman filter implementation of the model described in \cref{sec:nw_model}, which, as previously discussed, is a highly efficient estimation method.
%The first step to using the Kalman filter is to transform the data---that is, the observed travel times---into the same \emph{state space} as $\NWstate_{\ellc}$.

% The particle filter estimate of vehicle state makes it easy to estimate not only the vehicle's travel time but also any transformations of it. The transformation we need is the inverse of \cref{eq:nw_state_logtransform}, for which we have the posterior distribution
% \begin{equation}\label{eq:pf_log_tt_posterior}
% p(\log(\Vttobs_{\ellc}^m - T_\ell^\text{min}) | \Vobs_{1:c}^m)
%     \approx
%     \sum_{i=1}^{N^m} \Pwt_c
%         \dirac\left(
%             \log(\Vttobs_{\ellc}^m - T_\ell^\text{min}) -
%             \log(\Vttobs_{\ellc}^{\vi m} - T_\ell^\text{min})
%         \right).
% \end{equation}
% The posterior mean, which is used as the travel time observation, is
% \begin{equation}\label{eq:nw_tt_trans_obs_mean}
% \bar\Vttobs_{\ellc}^m =
%     \E{\log(\Vttobs_{\ellc}^m - T_\ell^\text{min}) | \Vobs_{1:c}^m} =
%     \sum_{i=1}^{N^m} \Pwt_c \log(\Vttobs_{\ellc}^{\vi m} - T_\ell^\text{min})
% \end{equation}
% and similarly we can estimate the measurement error from the variance of the distribution,
% \begin{equation}\label{eq:nw_tt_trans_obs_err}
% \left(\Vtterr_{\ellc}^m\right)^2 =
%     \Var{\log(\Vttobs_{\ellc}^m - T_\ell^\text{min}) | \Vobs_{1:c}^m} =
%     \sum_{i=1}^{N^m} \Pwt_c \left(\log(\Vttobs_{\ellc}^{\vi m} - T_\ell^\text{min}) - \bar\Vttobs_{\ellc}^m\right).
% \end{equation}

The measurement matrix (\cref{sec:kf} on \cpageref{sec:kf}) is unity since the observations are now directly observations of the state we are estimating. Similarly, the transition matrix is also unity, which we get from \cref{eq:nw_state_markov}. We now have everything we need to implement a Kalman filter on $\NWstate_{\ellc}$, assuming (for now) that $\NWvar_{\ellc}$ is known.


\subsection{Predict step}
\label{eq:kf_predict}

The state prediction is straightforward, since we are assuming travel time is constant over short time periods. The estimated state has mean
\begin{equation}\label{eq:nw_state_mean_est}
\hat\NWstate_{\ellc|c-1} =
    \E{\NWstate_{\ellc} | \NWobs_{\ell \boldsymbol{\cdot}}^\boldsymbol{\cdot}}
\end{equation}
and variance
\begin{equation}\label{eq:nw_state_mean_est}
\NWstatevar_{\ellc|c-1} =
    \Var{\NWstate_{\ellc} | \NWobs_{\ell \boldsymbol{\cdot}}^\boldsymbol{\cdot}}
\end{equation}
which are predicted using
\begin{equation}
\label{eq:nw_kf_predict}
\begin{split}
\hat\NWstate_{\ellc|c-1} &=
    \hat\NWstate_{
\ellc-1|c-1} \\
\NWstatevar_{c|c-1} &= \NWstatevar_{c-1|c-1} + \left(\NWtdiff_c\NWnoise_c\right)^2
\end{split}
\end{equation}
What this looks like is shown in \cref{fig:nw_kf1}.

<<nw_kf,message=FALSE,echo=FALSE,fig.height=3,fig.width=8,fig.cap="Network state prediction, with the state history mean and variance shown by the black line and shaded gray region, respectively. The predicted mean is shown by a red dot, and the shaded pink region represents predicted state variance. The dashed blue line in the bottom plot represents the historical mean travel time as a function of time.",fig.subcap=c("Constant travel time model", "Historical change based model"),cache=TRUE,fig.ncol=1>>=
suppressPackageStartupMessages(library(tidyverse))
set.seed(345)
d <- tibble(
    t = 1:30,
    x = 30 + cumsum(c(
        rnorm(15, 0, 1),
        rnorm(15, c(-0.5, 0), 1)
    )),
    err = runif(30, 3, 4)
)
d2 <- d[30, ] %>%
    bind_rows(tibble(
        t = 35,
        x = d$x[30],
        err = d$err[30] + 3
    ))
p <- ggplot(d, aes(t, x)) +
    geom_ribbon(aes(ymin = x - err, ymax = x + err),
        fill = "#eeeeee") +
    geom_path() +
    geom_point(data = d[30, ]) +
    theme_minimal() +
    theme(panel.grid = element_blank()) +
    scale_x_continuous(breaks = NULL) +
    scale_y_continuous(breaks = NULL) +
    xlab("Time (s)") + ylab("Travel time (s)")

p + geom_ribbon(aes(ymin = x - err, ymax = x + err),
        data = d2, fill = "red", alpha = 0.1) +
    geom_path(data = d2, color = "red", lty = 2) +
    geom_point(data = d2[2,], colour = "red")

dd <- tibble(t = seq(1, 35, by = 0.1)) %>%
    mutate(x = dnorm(t, 38, 6)) %>%
    mutate(x = 32 - 10 * x / max(x))
dx <- dd %>% filter(t %in% c(30, 35)) %>%
    pluck("x") %>% diff
d2$x[2] <- d2$x[1] + dx
p + geom_ribbon(aes(ymin = x - err, ymax = x + err),
        data = d2, fill = "red", alpha = 0.1) +
    geom_path(data = d2, color = "red", lty = 2) +
    geom_point(data = d2[2,], colour = "red") +
    geom_path(data = dd, lty = 2, lwd = 1.5, col = "steelblue")
@


\subsection{Update step}
\label{eq:kf_update}

Updating the \kf{} involves taking the predicted state and updating it using ``observations'' of travel time along road segments. These we have obtained from the \pf{} in \cref{sec:vehicle_travel_times} and transformed to the log-space. However, it is possible to have multiple observations per road segment
in one update period, as it is common for buses to travel one behind the other, particularly where there are bus lanes. Therefore, for each individual road segment, we have a vector of observations, one for each vehicle $v \in V_{\ell c}$ passing through that segment in the time interval $(t_{c-1}, t_c]$,
\begin{equation} \label{eq:nw_seg_obs}
\NWobss_\ell_c = \bigcup_{v\in V_{\ell c}} \NWobss_{\ell c}^v
\end{equation}
which can be the empty set $\NWobss_\ell_c = \emptyset$ if no vehicles travel through a segment in the interval. For the measurement error $\NWErr$, we account for between-vehicle variability by adding the sources of error,
\begin{equation}\label{eq:nw_err_sum}
\NWErr_{\ellc}^m = \NWvar_{\ellc}^2 + \left(\NWerr_{\ellc}^m\right).
\end{equation}
\textcolor{red}{
    (I think this should go a bit later.)
}


In order to update the network, we need to account for each observation. One way of doing this would be to combine the observations into a single estimate and use that; alternatively, we could use the \emph{\infil{}} \citep{cn}, which has the advantage of letting us sum up the information from multiple observations easily. Since we are dealing with a univariate state, this is a viable option as ``inverting'' a $1\times1$ matrix is easy to compute.

To employ the \infil{}, we need to complete four steps:
\begin{enumerate}
\item transform the state space into information space,
\item transform the observations into information,
\item update the information space using the observation information, and
\item back-transform the updated information space to the original state space.
\end{enumerate}


The first step involves converting the predicted state vector and covariance matrix into  nformation space. This involves the inversion of the covariance matrix $\NWvar_{\ellc|c-1}^{-1}$, yielding the information matrix
\begin{equation}\label{eq:nw_if_inf_matrix}
\NWinfmat_{\ellc|c-1} &= \NWstatevar_{\ellc|c-1}^{-1}
\end{equation}
and information vector
\begin{equation}\label{eq:nw_if_inf_vector}
\hat\NWinfvec_{\ellc|c-1} &= \NWstatevar_{\ellc|c-1}^{-1} \hat\NWstate_{c|c-1}
\end{equation}


Converting the observations into information follows the same formula. Note first that the error needs to account for both measurement error and between-vehicle error, which, since these are both assumed Gaussian and by definition are independent, the total variance is simply the sum of the two respective variances. The observation information matrix is therefore
\begin{equation}\label{eq:nw_if_inf_obsmatrix}
\NWobsinfmat_{\ellc}^m &= (\NWvar_{\ellc} + \NWerr_{\ellc}^m)^{-2}
\end{equation}
and the observation information vector is
\begin{equation}\label{eq:nw_if_inf_obsvector}
\hat\NWobsinfvec_{\ellc}^m &= (\NWvar_{\ellc} + \NWerr_{\ellc})^{-2} \hat\NWobs_{\ellc}^m
\end{equation}
Combining these by summation over vehicles yields the complete information matrix and vector for the time period $(t_{c-1},t_c]$, which are, respectively,
\begin{equation}\label{eq:nw_if_obsupdate_matrix}
\NWobsinfmat_{\ellc} &= \sum_{m\in V} \NWobsinfmat_{\ellc}^m
\end{equation}
and
\begin{equation}\label{eq:nw_if_obsupdate_vector}
\NWobsinfvec_{\ellc} &= \sum_{m \in V} \NWobsinfvec_{\ellc}^m
\end{equation}



The state update is now also a case of adding the total information to get
\begin{equation}
\label{eq:nw_if_update}
\begin{split}
\NWinfmat_{\ellc|c} &= \NWinfmat_{\ellc|c-1} + \NWobsinfmat_{\ellc} \\
\hat\NWinfvec_{\ellc|c} &= \hat\NWinfvec_{\ellc|c-1} + \NWobsinfvec_{\ellc}
\end{split}
\end{equation}
Note that, in situations where no data is observed for a given segment, the information for that segment is zero, so we remain with the predicted state.


Finally, we back-transform the information into the state space,
\begin{equation}
\label{eq:nw_if_statespace}
\begin{split}
\hat\NWstate_{\ellc|c} &= \NWinfmat_{\ellc|c}^{-1} \hat\NWinfvec_{\ellc|c} \\
\NWstatevar_{\ellc|c} &= \NWinfmat_{\ellc|c}^{-1}
\end{split}.
\end{equation}

The main constraint on the model is the dependence on $\NWvar_{\ellc}$ and $\NWnoise_{\ellc}$; however, before we consider the estimation of these values, we will first apply the Kalman filter model to the simulated date (for which the parameter values are known).


<<nw_simdata_fit,echo=FALSE,cache=TRUE,message=FALSE,warning=FALSE,fig.width=6,fig.height=2,fig.align="center",out.width="\\textwidth",fig.cap="Fitted KF to simulated data.",fig.subcap=c('Estimted mean travel time.', 'Predictive distribution of travel times.'),fig.ncol=1,fig.sep=rep("\\\\", 4)>>=
source("sim_data.R")
library(tidyverse)
sim <- get_simulation()

t <- sim$t
th <- t %/% 1
tm <- (((t %% 1) * 60) %/% 5) * 5
t30 <- th + tm / 60
N <- nrow(length(sim$b))
M <- length(unique(t30))
kf.fit <-
    tibble(
        time = sort(unique(t30)),
        delta = c(0, diff(sort(unique(t30))))/60*5,
        beta = rep(NA_real_, (M)),
        beta_hat = rep(NA_real_, (M)),
        P = rep(NA_real_, (M)),
        P_hat = rep(NA_real_, (M)),
        B_hat = 1 / P_hat,
        b_hat = beta_hat / P_hat,
        B = 1 / P,
        b = beta / P
    )

kf.fit$beta[1] <- sim$pars$mu + exp(sim$truth$b[1])
kf.fit$P[1] <- 500

# q value is about 5, var(exp(sim$truth$b)) = 730 -> every 5min
q <- 5
phi <- sim$pars$phi
mu <- 14

# convert all data to information
kf.data <-
    tibble(
        time = t30,
        t = as.integer(as.factor(t30)),
        b = sim$b - mu,
        E = 5.0
    ) %>% mutate(
        I = 1 / (E^2 + phi^2),
        i = b / (E^2 + phi^2)
    ) %>% arrange(t)

kf.fit <- kf.fit %>%
    left_join(
        kf.data %>% group_by(t) %>%
            summarize(time = first(time), Z = sum(I), z = sum(i)),
        by = "time"
    )

t0 <- proc.time()
for (i in 2:M) {
    # predict
    kf.fit$beta_hat[i] <- kf.fit$beta[i-1]
    kf.fit$P_hat[i] <- kf.fit$P[i-1] + (kf.fit$delta[i] + q)^2

    # update
    kf.fit$B_hat[i] <- 1 / kf.fit$P_hat[i]
    kf.fit$b_hat[i] <- kf.fit$beta_hat[i] / kf.fit$P_hat[i]
    kf.fit$B[i] <- kf.fit$B_hat[i] + kf.fit$Z[i]
    kf.fit$b[i] <- kf.fit$b_hat[i] + kf.fit$z[i]

    # untransform
    kf.fit$beta[i] <- kf.fit$b[i] / kf.fit$B[i]
    kf.fit$P[i] <- 1 / kf.fit$B[i]
}
time_kf <- proc.time () - t0

library(ggplot2)

truth <- tibble(time = sim$truth$t, b = sim$pars$mu + exp(sim$truth$b))
ggplot(kf.fit[-1,], aes(time)) +
    # geom_point(aes(y = mu + b), data = kf.data) +
    geom_ribbon(aes(
            ymin = mu + truncnorm::qtruncnorm(0.025, 0, Inf, beta_hat, sqrt(P_hat)),
            ymax = mu + truncnorm::qtruncnorm(0.975, 0, Inf, beta_hat, sqrt(P_hat))
        ),
        fill = "blue", alpha = 0.2) +
    geom_path(aes(y = mu + beta_hat), col = "blue") +
    geom_ribbon(aes(
            ymin = mu + truncnorm::qtruncnorm(0.025, 0, Inf, beta, sqrt(P)),
            ymax = mu + truncnorm::qtruncnorm(0.975, 0, Inf, beta, sqrt(P))
        ),
        fill = "red", alpha = 0.2) +
    geom_path(aes(y = mu + beta), col = "red") +
    geom_path(aes(y = b), data = truth, lty = 2) + #, colour = "limegreen") +
    theme_classic() +
    xlab("Time") + ylab("Travel time (seconds)")

ggplot(kf.fit[-1,], aes(time)) +
    geom_point(aes(y = mu + b), data = kf.data) +
    geom_ribbon(aes(
            ymin = mu + truncnorm::qtruncnorm(0.025, 0, Inf, beta, sqrt(P) + phi),
            ymax = mu + truncnorm::qtruncnorm(0.975, 0, Inf, beta, sqrt(P) + phi)
        ),
        fill = "red", alpha = 0.2) +
    geom_path(aes(y = mu + beta), col = "red") +
    theme_classic() +
    xlab("Time") + ylab("Travel time (seconds)")

@

The \kf{} was fitted to the simulated data using the same values of $\NWnoise$ and $\NWvar$ that were used to generate the data, with the estimates of $\hat\NWstate_{c|c-1}$ and $\hat\NWstate_{c|c}$ shown by solid blue and red lines in \cref{fig:nw_simdata_fit1}, respectively, along with the associated uncertainty as estimated by $\NWstatevar_{c|c-1}$ and $\NWstatevar_{c|c}$, with the simulated true mean shown by a dashed black line. We see that the 95\% credible interval mostly captures the true value of $\NWstate_{c}$, with some difficulty around the peak. \Cref{fig:nw_simdata_fit2} shows the posterior estimate of $\hat\NWstate_{c|c}$ along with the posterior predictive distribution of $\NWobs_c^m$; that is, using the 95\% region defined by the sum of $\NWstatevar_{c|c}$ and $\NWvar^2$, the latter of which is known from the simulation. Almost all of the observation points lie within the 95\% predictive region, which affirms that, given we know the network parameters $\NWnoise$ and $\NWvar$, we can recover the underlying network state by using a \kf{} in \rt{}.
